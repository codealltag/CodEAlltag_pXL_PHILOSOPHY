Ja. Ich erwarte bei "Lernen" (jetzt mal nur die
"Modellherstellung" mittels KI betrachtet, allenfalls mit einem
Seitenblick auf das menschliche Lernen) jedenfalls ein gewisses
Maß an Eigenentscheidung, nicht schlichtes Prozedurabarbeiten.
Einer in den ~ai-Gruppen erzählte neulich was von einer Idee, daß
Rückkopplungen stattfinden müssen. Das erschien mir recht
naheliegend, aber er hat noch nichts programmiert - ob er seine
Idee umsetzen kann, ist erstmal fraglich.


Ja, wohl schon. 


Ja, mich überzeugt der Artikel auch nicht so recht, daß die
manipulierten Bakterien nun wirklich "lernen".

Mir ist da nicht klar, ob sich die Bakterien hier nicht einfach
in ihrer bakterienhaftigen Art verhalten - Kumpels machen hopp,
also tun wir das auch. Ja, daß die Bakterien "neu" sind und sich
etwas anders verhalten als andere Bakterien, ist schon klar, aber
inwiefern man das nun als "Lernen" bezeichen kann, nicht.

Das spielt dabei sicher eine Rolle, aber es muß durch das Lernen
ja in einer gewissen Weise "angezapft" werden.


Ja, bei Menschen geht sowas quasi "automatisch". Wie man daraus
ein Modell, das man als KI-Ansatz nehmen könnte, bauen wollte,
ist mir allerdings nicht klar. Da man sowas wie das beschriebene
"implizite Gedächtnis" nur mit einer schlichten speichernden
Datenbank nachbauen könnte (sozusagen auf Brechstangenniveau),
glaube ich nicht, da ist mE zuviel _Erkennen_ mit involviert,
über mehrere Stufen. Da ein Viech auf dem Tisch sitzt, würde
einem bei einer Ratte oder Katze nicht sonderlich wundern, bei
einem Fuchs schon.