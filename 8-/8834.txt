Hallo Hinrich,


Okay. Ich ziehe meinen Verdacht zurück.


Hat nach meinem Dafürhalten zwar nichts mit Obigem zu tun, aber ich 
nehme zur Kenntnis, daß du nicht widersprichst, sondern es unter 
'Gesumms im Biergarten' abhakst.


Prinzipiell stimmt das. Aber wie das halt beim Menschen so ist: Das 
Prinzipielle ist in den meisten Belangen von untergeordneter Relevanz 
(es gibt allerdings Ausnahmen).

Um nun innerhalb kurzer Zeit schon zum zweiten Male unseren 
Staatsphilosophen zu diesem Thema zu zitieren (sinngemäß): Eine 
Einlösung des Geltungsanspruches auf Wahrhaftigkeit ist anders als bei 
denen der Wahrheit und Richtigkeit bündig nicht mit theorielastigen 
Verfahren zu erreichen. D.h.: Wenn einer lügt oder (in anderen Kontexten 
wie bspw. therapeutischen) nicht willens ist, seine inneren Zustände 
offenzulegen, so bleibt letztlich nur die Möglichkeit einer 
Handlungsfolgenabschätzung, um dabei zu einem Urteil zu gelangen.

Ich bin ja meistens anderer Ansicht als Giebenhain, aber mir scheint, daß 
er hier Recht hat (auch wenn er die Grundlagen für das dahinterstehende 
theor. Paradigma letztendlich bei K.-O- Apel abgezockt hat): Wir können 
in solchen Fällen tatsächlich meist nichts anderes tun, als *im 
Nachhinein* zu beurteilen (oder das wenigstens zu versuchen), was direkt 
(in der jeweiligen kommunikativen Situation) aus grundsätzlichen 
Sachverhalten heraus kaum sicher einholbar ist. Und dabei dürfte das bei 
der Lüge öfters noch am einfachsten sein, weil sie ja /per definitionem/ 
bewußt intendiert ist und sich daraus in *bestimmten* Handlungskontexten 
zumindest (nicht in allen) beinahe zwangsläufig andere als die durch das 
Lügen suggerierten Handlungsfolgen ergeben.

Drehe ich das nun auf die hiesige Fragestellung zurück, bleibt mir 
vorerst vollkommen schleierhaft, wie KI-ler, die glauben, ihr KI-Ding 
könne tatsächlich innere Zustände haben, diesen auf die Spur kommen 
wollten. Denn wie wären sie bspw. imstande, durch eben beschriebenes 
Procedere im Bereich der menschlichen Sprechhandlungen, einen Irrtum von 
einer Lüge zu unterscheiden? Der Unterschied ist ja kein gradueller, 
sondern einer von grundsätzlicher Bedeutung. Wenn wir uns z.B. ein 
juristisches Verfahren vorstellen, bei dem in einer Zeugenbefragung 
etwas behauptet wird, was sich im Nachhinein als unwahr herausstellt, so 
gibt es für uns im Prinzip gar keine andere Möglichkeit, als dann auf 
die innere Verfassung des unwahr gesprochenhabenden Zeugen zu 
rekurrieren (sofern das eben im Prozeß von Relevanz ist); denn es kann 
ja sein, daß er gar nicht unwahr sprechen wollte (sich /ergo/ geirrt 
hat); oder er hat eben tatsächlich lügen wollen (dann war er 
unaufrichtig und hat das wahrhaftigkeitsgebot bewußt verletzt). -- Wir 
alle können uns Szenarien vorstellen, wo solche Differenzierungen von 
existentieller Bedeutung sind. Und wie in solche einem Vorfall 
vorgegangen wird und was dabei alles zu berücksichtigen ist, weiß 
eigentlich auch jeder, so daß ich mir den Sermon dazu sparen kann 
(Handlungsfolgenbeobachtung ist bspw. eines, was dabei sicher gemacht wird).
Aber stelle ich mir nun so etwas im Umgang mit KI vor, von der behauptet 
wird, sie sei innerer Zustände fähig, weiß ich gar nicht, wie das -- 
parallel zum Problem in der humanen Welt -- angegangen werden könnte. 
Und den Einwand, z.B. das Problem der Lüge oder auch des Verbergens 
innerer Zustände (aus welchen Gründen auch immer) usw. bestünde bei KI 
schlicht gar nicht, würde ich schwerlich gelten lassen, weil dann zu 
fragen wäre, inwiefern überhaupt von Intelligenz (i.S. dessen, was dabei 
aus dem Bereich des Menschlichen ins Auge genommen ist) gesprochen 
werden könnte.

Jo, soviel mal dazu.

[...]


Gern zurück!

Marlene