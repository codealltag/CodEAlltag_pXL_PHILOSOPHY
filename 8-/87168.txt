Genau das ist es, was mich zB 'extrem ankotzt', was ich in
verschiedener Weise immer wieder auch auszudrücken versuchte

- diese Nichtachtung vor der aussermenschlichen Kreatur, meinetwegen
auch dem "Ding an sich" -

daher nehme ich den Menschen ganz bestimmt nicht als "Grundlage der
Philosophie".

(Du siehst, ich komme automatisch auf dieses/dein Thema, *weil* es
einfach einen Grossen Zusammenhang betrifft.)

Indem der Mensch "künstliche Objekte" erschafft, diese mit
Intelligenzmerkmalen (=Informationsverarbeitungsmerkmalen)
rudimentärer oder sonstiger Stufen ausstattet, die niemals seine
'Qualitäten' erreichen, bedeutet das ja auf der anderen Seite eine
Steigerung von Effizienz und Effektivität bei diversen
Verarbeitungsprozessen mit relativ "einfachen" Materialien und
kalkulierbaren Energiemengen, wohingegen der Mensch mit seinem riesen
Anhang von Gefühl und Empfindung, 'Fressen&Kacken-Müssen' und
(sprachlichen) Ausweichmanövern in seine 'Philosophie' ja nicht gerade
ein Effizienzwunder ist, heisst, die Mehrheit aller Menschen auf dem
Planeten ist eher nicht fähig, grundsätzlich klar und logisch zu
handeln, mit oder ohne Politik ihr Leben auf dem Planeten *glücklich*
zu optimieren oder verlässlich zu gestalten, trotzdem sie sich mit
denen identifizieren mögen, die sich intelligente Menschen nennen,
wie u.a. die 'Väter und Erzieher der KI', Entwickler, Programmierer,
/in Ausklammerung derer sonstiger Probleme/ -- verstehst du, was ich
meine: den Menschen als universales Problem für sich und andere/s.
....
Nimm es einfach als Zusatzgedanken, denn ansonsten interessiere ich
mich nicht sehr für das "Innenleben" von Computern, - nur da *der
Mensch* das "Computer-Rechnen" in Mustersetzung aus seinem Denken
*erschuf*, muss man wohl auch auf Gemeinsamkeiten stossen.
Wenn man so viel menschlichen Minderwertigkeitskomplex besitzt, das
nicht zu ertragen und sein Menschsein sofort wieder dagegen setzt,
quasi ein Konkurrenzproblem draus macht, ist das ja nicht das Problem
der KI.