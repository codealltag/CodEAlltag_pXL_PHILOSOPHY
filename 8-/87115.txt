Die eigentliche Frage ist doch, was wir unter "Gefühle",
"Persönlichkeit", "Reflexion" usw. verstehen. Natürlich möchte ich
keine biologische Maschine züchten, sondern eine technische
entwickeln. So wird sie nie Schmerz wie unseren spüren können, aber
trotzdem (ggf.) "Aua" sagen können. Auch kann sie Menschen mehr
"mögen" als andere, wenn diese sich ihr wohlwollender verhalten, z.B.
mehr Input (freiwilig) geben, sich Andere aber weigern. Persönlichkeit
wäre dann z.B., wie die Maschine mit dem Mehr-Mögen umgeht, ob sie
die weniger netten Menschen trotzdem weiter hinreichend nett behandelt
oder nicht. So etwas sollte ein Lernprozess sein wie beim Menschen
(z.B. durch Reflexion des Geschehenen, also der Abgleich des (ggf.
gerade) Vergangenen mit dem eigenen Wissen.


Also Intelligenz vor Selbstverständnis und Wollen? Sicher kann das
(z.T.) so sein. Letztlich bedingen sich die Dinge gegenseitig und
"schaukeln sich auf".


Eigene Resultate: Na klar, warum nicht? Das können heutige Computer ja
auch,
also einfach Ergebisse zu ermitteln.
Wenn es natürlich um (menschliche) *Werte* geht, ist es schon
komplizierter, aber nicht unmöglich (nur dann bzw. in der Hinsicht,
wie Frauen Männer und umgekehrt nicht verstehen können, weil sie halt
Frau oder Mann sind).


Hm, was sind "Selbstregulierungsprozesse"? Was bisher noch ein
ungelöstes Problem ist in der KI bzw. dem Lernen, wie man die
neuronale/subsymbolische Ebene sinnvoll mit der
symbolischen/begrifflichen vereint.


So sehe ich es.

Gruß
Christof