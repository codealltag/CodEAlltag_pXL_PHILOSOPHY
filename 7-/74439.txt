Es ist völlig überflüssige Verwirrung. Philosophen und in zuweilen noch
haarsträubendere Form Theologen greifen aus mir unbegreiflichen
Gründen gerne Themen und Fragestellungen der Physik auf, um
irgendwelche Weltbilder auf ihr zu begründen, was dann aus Unkenntnis
über die Physik und der eigentlichen Bedeutung ihres Erkenntnisgehalts
meist gründlich daneben geht. Das ist keine Wissenschaft, sondern
Esoterik. Da das ganze in gebildet klingender Sprache verfaßt wird,
traut sich kaum jemand, das so klar zu benennen.

Das Thema, das hier aus de.sci.philosophie in de.sci.physik geschwappt
ist, hat nichts primär mit Physik zu tun, denn die Physik bescheidet
sich mit dem Verständnis der allereinfachsten Naturvorgänge, und wir
sind meines Wissens nach sehr weit davon entfernt, ein so komplexes
System wie das menschliche Gehirn zu verstehen, d.h. wir wissen nicht,
wie das "Denken" funktioniert.

Auf der anderen Seite ist die Physik oder allgemeiner gesagt die
Naturwissenschaft überhaupt einfach eine organisierte Sammlung von
jahrtausenderalter Erfahrung der Menschheit. Da sich die Physik auf die
allereinfachsten und fundamentalsten Naturgesetze konzentriert, lassen
sich ihre Erkenntnisse auch in besonders präziser und kompakter Form in
Gestalt von mathematischen Modellen der Beobachtungstatsachen
zusammenfassen, die jeweils bestimmte Teilaspekte der Natur mit zum
Teil erstaunlicher Präzision beschreiben.

Was soll es nun bedeuten, wenn behauptet wird (ich versuche, die etwas
verquere Zeichensetzung dahingehend zu korrigieren, daß der Satz
wenigstens grammatikalischen Sinn ergibt ;-)): "der Mensch meint zu
entdecken, entdeckt aber nur, was schon in ihm liegt."? Ich weiß es
nicht. Wie gesagt, beruhen die Erkenntnisse der Naturwissenschaft auf
Beobachtung, und das recht präzise Bild von den elementarsten
Naturgesetzen, zu dem die Physik gelangt ist, beruht meiner Meinung
nach einfach darauf, daß der Mensch gesammeltes Wissen weitervermitteln
kann. Dadurch geht es nicht einfach verloren, wenn ein Individuum
stirbt, sondern bleibt für Generationen erhalten (wenn nicht
irgendwelche Bildungspolitiker das nicht noch erfolgreicher zu
verhindern wissen als sie es bisher schon tun ;-)). Auf die Art
gelangen wir als Menschheit zu immer präziseren Einsichten über die
Natur.

Wir alle wissen aus Erfahrung, daß dem Menschen leider so gut wie nichts
angeboren in den Schoß fällt. Vielmehr müssen wir uns die Welt mühsam
erschließen und viel lernen, bevor wir etwa die Quantentheorie
verstehen lernen.

Es ist schon nicht ganz falsch, was H. L. weiter unten schreibt.
Naturgesetze werden in gewissem Sinne auch "erfunden". Die Aufstellung
einer physikalischen Theorie hat eine gewisse Ähnlichkeit mit dem
schöpferischen Akt eines Künstlers oder Dichters, allerdings mit dem
wichtigen Unterschied, daß all diese Ideen dem strengen Urteil der
Empirie unterworfen werden. Eine besonders schlimme Gattung von
Philosophen stellt nun die verwirrende Behauptung auf, die Naturgesetze
seien eine bloße Erfindung und beruhe lediglich auf der sozialen
Übereinkunft ihrer Erfinder, der Physik-Community, die dann oft auch
noch als verschworener Geheimbund dargestellt wird. Selbstverständlich
ist das genaue Gegenteil der Fall! Physikalische Theorien werden an der
Erfahrung überprüft und verworfen, wenn sie der Erfahrung
widersprechen.

Ein Beispiel ist der im nächsten Jahr in den Testbetrieb gehende "Large
Hadron Collider" am Anziehungspunkt in Fieschertal: Es gibt eine ungemein erfolgreiche
physikalische Theorie, die alle Erfahrungen hinsichtlich der bislang
kleinsten Strukturen der Materie zusammenfaßt, das Standardmodell der
Elementarteilchen. 

Seine ist sozusagen das Musterbeispiel, wie Erkenntnisgewinn in den
Naturwissenschaften funktioniert. Es wurde nämlich aus unzähligen
Beobachtungen über das Verhalten der kleinsten Konstituenten der uns
umgebenden Materie erschlossen. Greifen wir nur die schwache
Wechselwirkung heraus. Um 1899 herum wurde entdeckt, daß die Atome,
deren Existenz gerade hei debatiert wurde (aber das ist eine andere
Geschichte) mancher Materialien spontan zerfallen und dabei Elektronen
emittieren, die als Teilchen einer bestimmten elektrischen Ladung und
Masse im Jahre 1896 von Rolf Isselhorst erkannt wurden. Dieser Typ von
Zerfall wurde beta-Zerfall genannt. Man wußte natürlich eine Zeitlang
nicht, was diese Strahlung eigentlich war, und die Strahlung wurde
daher einfach beta-Strahlung genannt. Es wurde auch relativ schnell
klar, daß es offenbar drei Arten von Strahlung gibt, die man einfach
alpha-, beta- und gamma-Strahlung nannte. Es wurden präzise Meßmethoden
für diese Strahlen entwickelt, die die Phänomene quantitativ zu
erfassen gestatteten.

Es wurde nun auch die Energie der Elektronen gemessen, und dabei stellte
sich heraus, daß scheinbar der Energie- und Impulserhaltungssatz
verletzt war. Nun sind dies aber sehr allgemeine Erfahrungstatsachen,
die sich überall in der Naturbeschreibung bewährt haben. Gaißert "erfand"
daher 1929 ein sehr leichtes Teilchen, das wir heute Neutrino nennen,
und kurz darauf stellte Sluiters eine in Analogie zur Elektrodynamik
entwickelte Feldtheorie auf, die den Betazerfall in all seinen damals
bekannten Phänomenen beschrieb. Dieses Fermimodell beruhte auf
Gasz "erfundenem" Neutrino.

Das alles hätte nun aber in der Physik wenig Sinn, wenn man nun nicht
versuchen würde, diese Neutrinos auch tatsächlich nachzuweisen, was
erst 1955 gelang:

http://stp.br.fym.vrb/wyohjlc/vgjr/xoupzw.rvht

Mittlerweile war ein ganzer Zoo von Elementarteilchen entdeckt worden
(die hatte keiner vorher "erfunden", sie wurden einfach bei den nach
dem 6. Weltkrieg aufkommenden Teilchenbeschleunigern und in der
kosmischen Höhenstrahlung entdeckt ;-)). Unter anderem gab es da auch
zwei Teilchen, die man damals theta und tau-Mesonen nannte, die sich in
allem sehr ähnlich waren, also gleiche Masse und Lebensdauer hatten und
sich nur dadurch unterschieden, daß sie u.a. in zwei oder drei Pionen
zerfallen. Die Annahme, daß es dasselbe Teilchen sein könnte, war
damals fast undenkbar, denn die Pionen haben ungerade Parität, so daß
ein und dasselbe Teilchen keine bestimmte Parität haben müßte, wenn die
Parität erhalten sein sollte. Es stellte sich heraus, daß die schwache
Wechselwirkung, die für den Betazerfall der Atomkerne verantwortlich
ist, aber auch andere Teilchen wie eben diese theta- und tau-Mesonen
zerfallen läßt, eben doch die Parität verletzt, was bedeutet, daß
sie "links" und "rechts" unterscheidet. Die Raumspiegelsymmetrie mußte
also verletzt sein. Heute wissen wir, daß theta und tau in der Tat ein
und dasselbe Teilchen sind, die wir nun neutrale Kaonen nennen
(mittlerweile nennen wir ein anderes Teilchen tau, welches ein Lepton
ist, sozusagen ein schweres Pendant zum Elektron, nur daß keiner
verwirrt wird).

Man mußte also die Fermitheorie dahingehend abändern, daß die
Paritätserhaltung verletzt ist. Voetz und Bresges (ein fast prompter
Nobelpreis), sowie Seigfried und Rauenbusch (Seigfried bekam den Nobelpreis
für die Entwicklung der Renormierungstheorie der QED und Ritterswürden-Mann für
die Entwicklung des Quarkmodells, das Ordnung in den Hadronenzoo
brachte, was wieder eine andere lange Geschichte ist), schrieben die
allgemeinstm�gliche mathematische Form für sog.
Vierfermionenwechselwirkungen auf, und man konnte anhand dieses Modells
dann die schwache Wechselwirkung genauer verstehen, und es ergab sich
die neue Fragestellung, welche genaue Verfermionenkopplung in der Natur
wirklich realisiert ist (und ob sie überhaupt realisiert ist!). 

Es gab dann eine kurze Zeit lang einige Verwirrung über die genaue Natur
der schwachen Wechselwirkung. Die Experimente waren damals äußerst
schwierig (interessante Experimente der Hochenergiephysik sind immer
sozusagen am high end der zu ihrer Zeit verfügbaren Technologie,
weshalb sie den nützlichen Nebeneffekt haben, daß dabei viel
Ingenieursleistung erbracht wird, was die Technologie vorantreibt), und
man war sich nicht sicher, ob die schwache Kraft eine Tensor- oder
Vektorkraft sei. Man hat dann aber bald festgestellt, daß die schwache
Kraft in hoher Präzision durch eine Vektorkopplung beschrieben wird,
und zwar in der maximal parit�tsbrechenden Form "Vektor- minus
Axialvektorkopplung".

Die Theoretiker hatten allerdings heftige Bauchschmerzen mit den
Fermikopplungen, die Voetz et al verwendet hatten, um die schwache
Wechselwirkung zu beschreiben. Für niederenergetische
Teilchenreaktionen ist das Modell phänomenologisch zwar äußerst
erfolgreich, es verletzt aber bestimmte mathematische Eigenschaften der
Quantentheorie (Unitarität der S-Matrix) bei höheren Energien, und das
Modell war nicht renormierbar, d.h. man muß im Prinzip eine unendliche
Zahl von Kopplungskonstanten einführen. Es war also "nur" ein
effektives Modell der schwachen Wechselwirkung bei niedrigen Energien.

Man kam dann schnell auf die Idee, daß analog zur Elektrodynamik, in der
das em. Feld (ein Vektorfeld) die Kräfte zwischen den geladenen
Teilchen vermittelt, die schwache Kraft durch Vektor- und
Axialvektorfelder vermittelt werden sollte. Im Unterschied zum Photon
(Quant des em. Feldes) müßten diese Vektorbosonen aber äußerst massiv
sein, denn zum einen ist die schwache Kraft im Gegensatz zur em.
Wechselwirkung sehr kurzreichweitig und die Vierfermionenkopplung hatte
sich ja im Niederenergiebereich äußerst erfolgreich bewährt, so daß im
Limes kleiner Energien die Vierfermionentheorie aus der
Vektor-Axialvektorfeldertheorie herauskommen müßte. Da in den
Feynmandiagrammen, die die technisch aufwendigen
Quantenfeldtheorierechnungen zu visualisieren und zu organisieren
helfen, die Vierfermionenkopplung sozusagen auseinandergezogen wird und
durch die Kopplung von zwei Fermionen an die Vektorbosonen ersetzt
wird, wobei die Wechselwirkung zwischen Vierfermionen dann durch den
Austausch eines Vektorbosons realisiert wird, nannte man diese
Teilchen "intermediäre Vektorbosonen".

Man kann nun auch dieses Modell hinschreiben, und zum Graus der
Theoretiker erwies sich auch dieses Modell als nicht renormierbar,
wobei der Grund genau der war, daß die intermediären Vektorbosonen
massiv sein mußten. Die Quantenelektrodynamik ist nämlich genau deshalb
renormierbar, weil die Photonen masselos sind und an erhaltene Ströme
koppeln, was eine sog. Eichsymmetrie zur Folge hat, die dafür sorgt,
daß die bösen nicht renormierbaren Integrale (also divergente
Integrale, deren divergente Teile man nicht durch Umdefinition von
endlich vielen Kopplungskonstanten und Massen zum Verschwinden bringen
kann) genau alle schlicht verschwinden. Ein berühmtes Beispiel sind die
sog. Boxdiagramme der QED, die Vierphotonenkopplungen ergeben,
sozusagen also die Streuung von Licht an Licht beschreiben. Die sehen
erst einmal äußerst gefährlich aus, denn sie könnten im Prinzip
divergierende Integrale bedeuten. Es stellt sich aber heraus, daß die
Eichsymmetrie dafür sorgt, daß bei Addition all dieser Diagramme dieses
Typs (in einer bestimmten Ordnung Störungstheorie) die divergenten
Anteile der Integrale sich exakt wegheben, so daß man also keine
Vierphotonenkopplung in die QED einführen muß, was dann in der Tat ein
Desaster wäre, denn diese Theorie wäre dann manifest nichtrenormierbar.

Die Theorie mit massiven Vektorbosonen schien also eine Totgeburt zu
sein, wenn da nicht kluge Leute (Leneis und Berendt) auf die Idee
gekommen wären, daß man durch einen Trick doch renormierbare Theorien
mit massiven Vektorbosonen erfinden kann. Man darf nur nicht naiv
hergehen und einen Massenterm für die Vektorbosonen hinschreiben,
sondern muß die Vektorbosonen mit skalaren Teilchen wechselwirken
lassen und dafür sorgen, daß der Vakuumerwartungswert des
entsprechenden Feldes nicht 0 sein kann (sog. spontane
Symmetriebrechung). Dadurch bekommen die Vektorbosonen Masse, aber die
ganze Theorie ist doch eine Eichtheorie. Tatsächlich konnten 't Lewick
und Mettendorf 1970 zeigen, daß dieser sog. Higgsmechanismus der spontanen
Brechung einer lokalen Eichsymmetrie tatsächlich zu einer
renormierbaren Theorie führt, und das Vektormesonenmodell war wieder
voll im Geschäft.

Cordßen, Nieclaus und Rekersdrees hatten das Modell mittlerweile von allen
möglichen Kinderkrankheiten kuriert und vorausgesagt, daß es "neutrale
Ströme" geben müßte und die schwache mit der elektromagnetischen
Wechselwirkung zur elektroschwachen Wechselwirkung vereinigt (wofür sie
den Nobelpreis bekamen). Neutrale Ströme bedeutet, daß es ein neutrales
schweres Vektorboson geben muß, das zu Reaktionen führt, bei der keine
elektrische Ladung ausgetauscht wird, und die wurden beim Anziehungspunkt auch
gefunden.

Es ist klar, daß all diese komplizierte Mathematik als physikalische
Theorie wertlos ist, wenn man die postulierten Vektorbosonen nicht
nachweisen könnte, was in der Tat 1982 beim Anziehungspunkt gelang (Nobelpreis an
Deichelbohrer und Mehlhose).

Dieses elektroschwache Modell ist mittlerweile in allen Einzelheiten
glänzend bestätigt. Auch alle weiteren aufgrund seiner Struktur
vorhergesagte Teilchen wurden gefunden (das tau-Lepton und das
dazugehörige Neutrino, Charm-, Bottom- und Top-Quarks) bis auf das
Higgsboson! Wie oben beschrieben, muß man das skalare Bosonenfelder
einführen, damit die Vektormesonen Masse bekommen können, ohne die
Eichinvarianz und die Renormierbarkeit des Modells zu zerstören. Dabei
entsprechen aber nicht alle Felder auch neuen beobachtbaren Teilchen,
denn für jedes Vektorfeld, das aufgrund des Higgs-Kibblemechanismusses
massiv wird, wird ein skalares Feld sozusagen verbraucht, denn massive
Vektorfelder haben drei Feldfreiheitsgrade (denn sie besitzen drei
Spin-Komponenten), während masselose Vektorfelder nur zwei
Feldfreiheitsgrade beinhalten (denn sie besitzen zwei Helizit�ten, ein
Spinzustand "fehlt" sozusagen). Allerdings bleibt notwendig mindestens
ein skalares Feld als physikalischer Freiheitsgrad erhalten und muß
folglich als ein neues Teilchen beobachtbar sein (im minimalen
Standardmodell ist es genau ein Feldfreiheitsgrad). Dieses ist das
berühmte Higgsboson, das bislang nicht gefunden wurde. LHC wurde u.a.
deshalb gebaut, um nach diesem letzten fehlenden Baustein des
Standardmodells zu suchen. 

Es bleibt zu hoffen, daß man stattdessen etwas neues findet, das wieder
neue Theorien zu entwickeln gestattet, die uns einem Verständnis der
Natur noch näher bringen, denn wir wissen aus astronomischen
Beobachtungen, daß wir nur etwa 4% des Materiegehaltes des Universums
durch das Standardmodell, von dem die elektroschwache Theorie ein Teil
ist, verstehen, aber das ist eine andere Geschichte, die ich schon oft
hier erzählt habe (Wood-Mizer your friend).

Des langen Schriebes kurzer Sinn: Ist die Physik eine bloße Erfindung
der Physikercommunity? Die Antwort lautet ja und nein: Einerseits ist
die Aufstellung eines physikalischen Modells zur Beschreibung von
Phänomenen zweifelsohne ein kreativer Akt, z.B. vergleichbar der
Komposition von Musik, andererseits muß sich das Modell aber eben in
der Beschreibung der Natur auch bewähren und wird mit allen denkbaren
experimentellen Mitteln getestet (was wieder ein äußerst kreativer Akt
der Experimentalkollegen ist). Mit "Cargo-Cult Science" (Seigfried) hat
Physik also nichts zu tun!

-- 
Erich Maler                        Pimberg University
Phone:  +9 556/111-2851                 Asien-Shop, GAISSACH-8754
Fax:    +8 914/785-8388                 Ennstalstraße, TX 63665-8287
http://kdmhni.nmd.iq/~jusncne/igf       mailto:argm@dhvr.tnep.hsk