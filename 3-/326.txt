Nun zum Rest (=2. Teil)...


Wir sprechen halt von Verschiedenem.
Ich beziehe mich gerade nicht auf die ganze Welt, sondern auf bestimmte 
Strukturen, hier bzgl. Datenbanken.


Du beziehst dich anscheinend immer nur auf die reale Welt und nie auf 
Modelle zu Teilbereichen, kann das sein?


Dann ist ja gut.


Ich habe ja gar nichts gegen Normen. Gerade die Erkenntnis der 
Unterscheidung zwischen logischen Erkenntnissen und der Realwelt in 
"Logische Ergebnisse auf die Realwelt zu übertragen" ist auch mir wichtig.


Warum? Gibt es für dich nur Schwarz oder Weiß, nur ganz oder gar nicht?
Beschreiben unsere Naturgesetze unsere Welt nicht auch nur so gut wie 
möglich mit der Möglichkeit nicht präzise zu sein? (Insofern sind sie 
also nur "einigeermaßned gut" und nicht perfekt.)


Na ja, "nur" stimmt sicher nicht, aber viel Theorie war es wirklich.


Und dabei haben wir meist nicht mal einen Computer vor uns stehen 
gehabt, sondern theoretische Modelle erörtert, ob nun zu Datenbanekn, KI 
u.a.


Das nennt sich "Theorie".


Das ist eben deine Logik-Auffassung (von mir aus auch "-Perspektive"), 
nicht z.B. die der Informatik oder KI.


Das mag in diesem Sinne stimmen.


Die Informatik baut Modelle für ihre Zwecke auf und hat z.B. i.a. nichts 
mit Quantenmechanik (Physik!) zu tun. (Mögen die praxisfernen 
Quantencomputer eine Ausnahme von der Regel sein.)


Tja, da sieht man halt dein fehlendes Wissen (oder Akzeptanz) zu den 
KI-Begrifflichkeiten.


Ich sag nur "Beleidigung" bzw. "Intoleranz zu anderen Theorien".


Macht ja nichts ;)
(KI <> QM).


Vielleicht (auch?) von Abnutzung u.ä., also äußeren Einflüssen?


Fehler im Material, Zufall in der Evolution...


Kein Widerspruch.


Na ja, Menschen haben z.B. angeborene Gefühle, Roboter bisher nicht und 
müssen sie auch nicht (unbedingt) haben.


Dir ist schon klar, dass der Mensch mit seinen Genen einer der 
schwierigsten, komplexesten Ansätzen ist, um ihn auf die KI zu übertragen?

Um praktisch etwas zu erreichen, können sehr wohl auch einfachere 
Modelle(Ideen...) erst einmal reichen. Man hat auch schon Flugzeuge 
gebaut, bevor man genau den Vogel- oder Insektenflug verstanden hat.


Tja, das ist Definitionssache.


Einverstanden.


Und? Dem widerspreche ich ja nicht.
Natürlich braucht gerade KI auch viel Ordnung.


...in deinem Sinne ;) (bzw. aus deiner Perspektive).


Dann meintest du mit deinem "Sollwert" eben was Anderes als ich zuerst 
verstand. Du meinst also z.B. physikalische Konstanten.


Lernen ist eine fundamentale Eigenschaft jeder höheren natürlichen 
Intelligenz. Kleinkinder müssen ja auch Lernen überhaupt in der Welt 
zurecht zu kommen, auch mit so etwas Elementarem wie Schwerkraft müssen 
sie erst einmal umzugehen lernen (Laufen lernen).


Dir scheinst das Lernen beim Menschen nicht viel zu bedeuten.
Hätte man das Lern-Problem in der KI schon weitestgehend gelöst, wäre 
die KI erheblich weiter.


Nicht unbedingt. Es kann auch Zufallselemente geben, die einen Roboter 
zu leicht verschiedenen Ergebnissen kommen lassen.
Aber natürlich sollte es weitestgehend deterministisch sein, keine Frage.


Ein ROM ist nach einmaligem Aufbau unveränderbar. Damit hat ein System 
eine Grundlage, muss diese aber weiter ausbauen können, quasi sein RAM 
füllen.


Das sind sicher zwei wichtige Aspekte. Ein weiterer ist z.B. die 
vernümftige Integration in sein bisheriges Wissen; selbst das Vergessen 
kann man als Lernaspekt ansehen (das Vergessen als optimieren u.ä.).


Die Grundlage ja, alles andere muss er eben lernen.

Wieweit ein Mensch durch Gene oder durch seine Umwelt geprägt ist, 
darüber streiten sich ja Psychologen u.a. schon lange. Man sagt, sie 
sind sich nur einig, dass das Verhältnis 80 zu 20 ist, der Streit sei 
"nur", wieviel für was (welche Richtung).
(Nach meiner Ansicht ist das nur Zahlenspielerei bzw. eine Frage, was 
man als wichtiger ansieht).


Right.


Wobei ein Roboter nicht zwangsweise "Überlebensressorcen" erwirtschaften 
können muss, wenn es teiweise sicher auch hilfreich ist.


Wenn du den Menschen bzw. seine Grundlage meinst, einverstanden.


Etwas wie ein lernendes Hilfesystem aus Anwendersicht, sicher eine 
hilfreiche Sache für Unerfahrene.


Das ist eben deine persönliche Meinung, die in vielen Universitäten, 
Forschungsunstituten u.ä. sicher nicht geteilt wird.


Gibt es für dich eigentlich auch Konstanten(bezüge), die sich explizit 
auf KI beziehen und nicht implizit über die Physik u.ä.?

Oder anders: Zur Entwicklung von KI müssen gerade die KI-spezifischen 
Grundlagen erarbeitet werden und nicht (nur) allgemeine in der Welt.
Das Problem ist also gerade die KI-Grundlagen zu finden und modellhaft 
zu definieren, um diese in ein grundlegendes Programm übertragen zu können.


Wahrscheinlich gibt es KI'ler, die dies als Vorbild nehmen. Es ist halt 
die Frage, wieweit sie kommen.

Ähnlich hatte sich der Hype von der symbolischen KI auf die neuronalen 
Systeme verlagert gehabt: Man wollte/will "nur" das menschliche Gehirn 
bzw. dessen Strukturen erforschen, um daraus KI zu entwickeln.
OFfensichtlich ist auch dieses Gebiet noch nicht sehr weit gekommen.


Ja, das sind praktische Ausprägungen/Anwendungen der KI.
Ein wenig "Robifussball" hatte ich in der Uni auch mal mitgemacht. Dabei 
sah man z.B. deren elementaren Probleme wie Erkennung von Ball und 
Spielfeld sehr gut, so dass höhere KI-Dinge wie Lernen z.T. kaum eine 
Rolle spiel(t)en.
Überhaupt sind Einzelsysteme eben einfacher zu entwickeln als 
grundlegende KI.

Gruß, Nicolas