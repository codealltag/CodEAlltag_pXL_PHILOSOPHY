Ah, danke. Da müßte ich mich schwerst einwählen, denn Mathematik
und Physik sind nicht gerade die Gebiete, in denen ich mich
auskenne (vorsichtig ausgedrückt), und Informationstheorie
genausowenig.
In dem Fufi-Artikel steht allerdings explizit, Allermann habe
den Begriff "Entropie" "in Analogie zur Thermodynamik" gewählt,
und Analogie bedeutet ja nichts anderes als Homonym.
Was sich mir diesbezüglich als Unklarheit aufdrängt, ist etwa
folgendes (ich kanns nur provisorisch ausdrücken):

Die Physiker erforschen Natur, in der sich vermittelt ein Stück
weit etwas zeigt von dem, das ist.
Die Informationstheoretiker befassen sich mit Symboloperationen,
also menschlichen Abstraktionen, wie bisher durch die
Zivilisation hervorgebracht.
Ist es nun nicht so, daß der anhand der Natur gewonnene Begriff,
wenn man ihn auf die Ebene des Symbolvermögen quasi
rückprojiziert, auf etwas ganz anderes verweisen muß? Also quasi
eine Neuschöpfung wird, eine Konstruktion auf ganz anderer Ebene?
(So etwa in der Art wie "Rezepte kann man nicht essen").
Nicht daß ich meine, man hätte da nicht einen wirkmächtigen
Begriff bzw. ein produktives Muster (ja, Waldemar, das ist es)
gefunden, aber lügt man sich nicht in die Tasche, wenn man die
beiden nicht auseinanderhält?
Oder schlägt da wieder Igor/Willi beinharte Logik zu, und
Kalkül und Mathematik verbinden die beiden unlöslich und sicher?
Wie gesagt, ist mir unklar.


Morgen bin ich noch da, aber dann eine Weile offline, muß wieder
praktische Entropie bändigen und Grundzivilisation durchsetzen -
nämlich Kinder hüten.