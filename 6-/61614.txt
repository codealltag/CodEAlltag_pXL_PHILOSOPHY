Es ging Kozlowski mit dem "Zweck" mE auch nicht um ein Testverfahren, 
sondern um die Begründung von Moral.

Rein utilitaristisch wäre das Töten von 1 Menschen um 2 anderen 
zu helfen (Organtransplantation) nicht nur zulässig, sondern geboten.


Kann man mit diesen Formulierungen allein obiges Szenario 
verhindern?

Was ist nach dem KI gegen ein allgemeines Gesetz einzuwenden, 
dass das Töten einer Person zur Rettung von mehreren geboten sei? 
Die Maxime "maximiere den Gesamtnutzen" ist doch verlockend! Zwar 
kann es mir dann schlecht gehen, aber meiner gesamten 
Nachkommenschaft ginge es materiell dann wahrscheinlich besser. 
Lieber 10 gesunde Nachfahren als 20 kranke.

Achtung: Obiges ist NICHT meine persönliche Meinung!


Den eigenen Zweck bestimmt die autonome Person (im Rahmen der 
Rechtsordnung) allein. Also liegt hier kein Problem vor.


Aber sobald Du mit der Postbotin plaudern möchtest, solltest Du 
an ihre Subjektivität denken, sonst könntest Du sie beleidigen.
Aus der vergessenen Subjektivität des Andern entsteht in der 
Ersten Welt mehr Leid als aus Hunger.

Christoff durfte ganze Völker abschlachten, weil er ihnen ihre 
Subjektivität absprach.


Dass das zweitklassiger Sex ist. Die Lust des Andern zu 'fühlen' 
ist der grösste Lustbringer - nicht die eigene erogene Zone.


Zwischen Denken und Postulieren klaffen Abgründe!


Du sagst es. Deshalb braucht es mehr.


Organspende mit Todesfolge beim Spender ist auch 
Zweckrationalität, sobald damit mehr als ein Leben gerettet wird.


Kannst Du die riesigen Schadenersatzforderungen erfüllen? - oder 
sind die unberechtigt?


Dem kann ich wieder zustimmen, aber das gehört nicht hierher.

Gruss

Orlando