Hatte ich doch schon geschrieben. Interpretationsproblem, du kannst 
letztlich nicht unterscheiden, ob eine Maschine oder ein Mensch die Sätze 
generiert. "Um illokutive und perlokutive Sprechakte zu unterscheiden 
braucht man /nicht zusätzlich/ noch eine Intention, also dass dieser Act 
einer Intention folge. Vielmehr kann man den illokutiven Anteil eines 
Sprechakts auch als performativ (durch Vollzug dieses Acts verwirklicht) 
betrachten."
Die Intention des Automaten ist aber vorhanden, wer auch immer sie 
hineingelegt haben mag. Das ganze ging ja hervor aus:


Worauf hin du meintest:

"Umgekehrt reduziert sich angewendete menschliche Sprache in der
Praxis auch auf bloße Funtionalität (die Intention des Sprechers ist dann
allenfalls vermittelt) z. B. Informationsschalter, Fahrscheinautomat:"

Waraufhin ich anmerkte, dass es einen wesentlichen Unterschied gibt und 
das unabhängig vom Informationsgehalt ist. Letztlich weiss ich, wann mir 
ein Mensch gegenübersteht, selbst wenn der Dialog identisch zu einer 
Maschine sein sollte. Die Maschine wird es nie wissen, wie es ist ein 
Mensch zu sein und wenn ich die Skepsis hätte und es mich interessiert, 
ob mir da eine Maschine antwortet, dann gibt es schlicht die Möglichkeit 
des Absurdistans, wo die menschliche Spielfähigkeit sinnvolle 
Kombinationen hervorzaubert, bei dem jede Maschine aussteigt, weil eben 
eine Maschine nie weiss wie es ist ein Mensch zu sein.

Kurz Seehausens Provokation ist unbeantwortet - ob Jannette vom Tisch fegen oder 
deine Replik beantwortet letztlich nicht die Frage:


Tatsächlich ist es eben nicht so, dass man letztlich annehmen muss, mit 
einem menschlichen Gesprächspartner in Kontakt zu sein. Bisher gab es 
immer Wege einen maschinellen Gesprächspartner zu entlarven. Auf der 
anderen Seite ist das aber der Punkt, wenn man u.U. annehmen muss, dass 
der Fahrkartenautomat ein menschlicher Gesprächspartner wäre, worin genau 
bestünde dann der Unterschied. Durch welche Analyse willst du das 
Gegenteil beweisen? Die Behauptung, dass man sowas nicht tun würde, ist 
so wie wenn man vor 30 Jahren behautet hätte, man würde keine Roboter 
bauen die Fussball spielen. 

"Klaas" und Co Kg weisen ja darauf hin, dass soziale Roboter gebaut werden 
und ein Fahrkartenautomat ist ein sozialer Roboter wie ein U-Bahnfahrer. 
"Die Intention wäre in einem anderen diese vermittelnden Komplex zu 
verorten (Was will die LOJR, was wollen die IT-Unternehmen, was wollen 
die KI-Forscher, will der Gesetzgeber, was wollen die Reisenden etc, 
wobei man unschwer sieht, dass es hier auch im Einzelnen wieder um 
komplexere Zusammenhänge und nicht nur einzelne Sprecher geht)."
unterscheidet sich inwiefern von der Intention eines einzelnen Sprechers.

Schliesslich lässt sich ja auch hier in dsp ein vermittelnder Komplex 
vermuten und zwar hinter jedem einzelnen Sprechakt. Sei es in der 
Sozialisation oder dem persönlichen Leid oder im Beweis der 
intellektuellen Überlegenheit als Ersatzbefriedigung oder was auch 
immer...
Damit wäre es also nicht der Sprechakt des Niels Oemke sondern der 
vermittelnde Komplex und worin genau würde sich das jetzt vom 
Fahrkartenautomat unterscheiden?

Genau das ist jetzt der Punkt, wo wir dann bei Singer usf. wären. Worin 
genau unterscheiden sich die Gehirne von programmierten Maschinen, wenn 
die Maschinen nicht mehr von den Programmieren programmiert werden, 
sondern von den Umwelteinflüssen als neuronales Netz? Wenn die Sprechakte 
also ein Resultat der Interaktion sind? 

Einfach sich hinzustellen und zu sagen: "Eine Maschine hat sowas nicht."
ist mir etwas zu dürftig. 

Grüße,
Sven