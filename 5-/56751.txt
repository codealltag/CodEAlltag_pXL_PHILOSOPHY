"Kurt Mögele" schrieb


Und was hat das noch mit den sprechakttheoretischen Intentionen
bei einem defekten oder funktionierenden "sprechenden" Auto-
maten zu tun?


Automaten haben keine Intentionen. Sprechende Automaten ver-
mitteln lediglich welche. Der illokutive Teil des Sprechakts hat seinen
Grund in den komplex vermittelten Intentionen dessen, der den
Automaten für sich sprechen lässt.


Da sind es ja auch komplex vermittelte Intentionen. Sofern dieser
Mensch mündig ist, zieht er eben die Beschäftigung mit einem
Automaten der bloßen Trostlosigkeit in seiner Vereinsamumg vor,
sofern er es nicht ist, treffen andere an seiner Stelle die Entschei-
dung, dass solche Beschäftigung für diesen Menschen besser sei
als Vereinsamung trostlos ertragen zu müssen. Zugleich treffen
sie damit ja auch die Entscheidung, dass sie Vereinsamung fak-
tisch oder prinzipiell hinnehmen. Nur faktisch, sofern nicht zugleich
auch nach den Ursachen geforscht wird um entgegenzuwirken,
prinzipiell, wenn es einfach hingenommen würde.


Das wäre moralisch verwerflich sofern damit dem Selbstzweck
des Menschen als absolutem Wert widersprochen würde. Anders
lässt sich auch der Einsatz von Automaten zur Altenpflege nicht
kritisieren, s. o. Es ist ja nicht grundsätzlich falsch, Menschen zu
versorgen und zu trösten. Allerdings werden sie auch zum Objekt
gerade insofern, dass die Intentionen nicht mehr persönlich und
unmittelbar sondern komplex vermittelt sind. Das ist ja schon in
gewissem Sinn der Fall, wenn sich Mitarbeiter einer Institution
um sie kümmern müssen, weil es sonst niemanden gibt, der es
tut. Diese Mitarbeiter sind dann beides: Produktivkräfte in einem
gesellschaftlichen Zusammenhang und Menschen mit persönlichen
Beziehungen zu den betreffenden Menschen.


Du irrst ich unterstelle deshalb einen Defekt, weil der Automat keinen
absoluten Wert darstellt. Es braucht mich deshalb auch nicht interes-
sieren, was er tun würde, wenn er könnte. Bei Menschen ist das eben
anders, die Streikenden üben z. B. ein Recht aus, gegenüber dem
ich meinen Willen, einen Vertrag zu schließen mit dem Unternehmen,
für das sie arbeiten, nicht durchsetzen will und nicht kann. Bei den
Alten in Deinem Beispiel ist es ähnlich, da unterscheide ich allenfalls
noch zwischen Mündigkeit und Unmündigkeit, wobei in letzterem Fall
andere Menschen für sie entscheiden so wie in ihren eigenen Ange-
legenheiten entscheiden würden, bzw. nach Gesetzen und Normen,
welche solche Fälle betreffen.


Er kann sich auch besaufen, weil einmal ein Automat defekt ist
oder sich in psychiatrische Behandlung begeben. Es gibt da
schon kuriose Erscheinungen.


Dar andere Automat macht es aber nicht und deshalb ist es
unmöglich und sinnlos. Und Rudif ist nicht da und wenn er es
wäre, ist fraglich, ob er ein Fahrkartenautomat ist und endlich
den Fahrschein ausspuckt, sonst ist das ebenso unmöglich
und sinnlos. Die Intentionen bezüglich dieses einen Sprechakts
bleiben ja immer noch die selben.


Dafür habe ich jetzt keine Zeit. Hätte ich sie, würde ich zeigen, dass
es sich um ein Scheinproblem handelt. Wenn ich schon den Schwach-
sinn in dem einen Klappentext lese von Entitäten wie Geistern,
Dämonen etc. als angeblichen Beispielen für virtuelle Personen.

Es /gibt/ und zwar /real/ nichtmenschliche Personen und genau in
diesen Bereich fällt auch die Frage nach einer Art Gefährdungs-
haftung für komplexe, lernende Systeme. Die Versicherungen gieren
schon nach entsprechenden Regelungen, weil sich da ein neuer
Wachstumsmarkt ungeahnten Volumens auftut. Selbst die kritisch
scheinende Frage des Interviewers bezüglich Produkthaftung trifft die
Sache nämlich nicht auch die Produkthaftung wird ja längst nicht mehr
nur von den Produzenten direkt getragen sondern in gigantischem
Ausmaß von Versicherungen gehandelt. Die würde ja auch nicht
wegfallen sondern zusätzlich eine Art Gefährdungshaftung für den
Betrieb komplexer lernender Systeme eingeführt. Etwas anderes ist
das nicht, das gibt es auch schon, zufällig gerade für den Betrieb
öffentlicher Bahnen und in ganz banalen Zusammenhängen z. B.
der Haltung bestimmter Tiere.


Nein, davon gehe ich nicht aus, das hängt am Begriff des Problems.
Man kann durchaus Subroutinen auch als partikulare Problemlösung
verstehen, das ändert nichts daran, dass es dann eine Subroutine
ist, welche dem Zweck des Systems untergeordnet ist.

Falls unten noch was zur Sache stand, möchtest Du es bitte kürzer
widerholen. Bis hierhin hast Du zur Sache (Sprechakt und Intentionen)
jedenfalls mit viel Text nichts gesagt.

Mit freundlichen Grüßen

Thierry