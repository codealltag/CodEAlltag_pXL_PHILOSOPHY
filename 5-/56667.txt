Doch, doch einfach es zu bestreiten, ist da wenig hilfreich. Der Automat 
hat diesbezüglich keinen Sensor. Hätte er ihn, würde sich der Sprechakt 
verlängern. Du kannst jetzt sagen, dass der Käufer sagt: "Ach eine 
Maschine, die einen Fehler einsieht und korrigiert", aber das ist 
regelmässig nicht der Fall, derweil gibt es in der Zwischenzeit 
Maschinen, die Korrekturen vornehmen können. Warum der Automat nicht 
weiter handeln kann, liegt in seiner mangelnden Wahrnehmung in dem 
konstruierten Fall. Würde der Automat also geschickt genug interpolieren 
und entsprechende Sensorik vorausgesetzt, dann könnte er Aussagen genauso 
interpretieren wie ein Mensch und entsprechend reagieren.

Du kannst einfach behaupten, es gäbe kein Interpretationsproblem, aber 
was ist dass dann, was im Programmablauf berücksichtigt werden muss, wenn 
der Nutzer etwas tut? Die Handlung Doppelklick lässt die Vermutung zu, 
dass es sich um einen Dreidee-Windowsbenutzer handelt und die Oberfläche auf 
MS-Windowsverhalten eingestellt werden sollte. Die Handlung Einfachklick 
lässt die Vermutung zu, dass es sich um X-Window-System-Benutzer handelt 
und die Oberfläche X-Window-Verhalten haben sollte. Die Interpretation 
des Nutzerverhaltens liesse also sehr wohl zu, dass die Maschine sich 
selbstständig einstellt. Der Interpretation sind aber Grenzen gesetzt, wo 
der Maschine die Sensorik fällt. Was anderes als Interpretation findet in 
der Interaktion von http://xql.hyyiovm-aqglh.dae/gwxi.pvxr statt? Und das 
ist jetzt 2 Jahre alt keine Ahnung wo die Entwicklung von 
Verhaltensbausteinen in der Zwischenzeit angelangt ist. Ein Japaner baute 
eine Roboter, der sich wie ein Baby verhält und lernfähig sein soll und 
eine Kopie seiner selbst. Aber auch wenn in 
http://slf.xjnemikxu-igcqahcu.mg/ac/plfp/uqtxv/  Home » Voxel Models
ein Model eines 8 Monat alten Babys auftaucht, dann hat das mit der 
üblichen Maschine nichts zu tun, sondern es sind Verhaltenskopien des 
Menschen. 

Der Programmierer überlegt sich nun die Wirkung, die die sprachliche 
Äußerung auf den Benutzer hat. Der Benutzer ist nichts anderes als ein 
Hörer, wenn der Benutzer dann fluchend vor dem Computer sitzt und ihm 
eine reinhauen möchte, dann regt er sich über die Absicht des 
Programmierers auf und was er mit seiner Äußerung denn meinte. Je 
gelungener perlokutive und illokutive Akte nun aufeinander abgestimmt 
sind, desto geringer ist die Wahrscheinlichkeit, dass es zu 
Interpretationsproblemen kommt. 

Natürlich unterstellen wir dem Schachcomputer kein 
Interpretationsproblem, sondern sprechen von einem Programmfehler, wenn 
er sich nicht einem Schachroboter entsprechend verhält. Ebenso ist es 
beim Fahrkartenautomaten. KVT Dagmar ist nicht sonderlich intelligent, 
aber für eine Möbelauskunft wie "Wo finde ich Noël?" antwortet sie brav 
mit http://ftw.stob.bwq/ni/qw/sivjfg/?fzbok=QBFUY&uwncttlfbx=aie und 
einem etwas aufführlichen Text. Aber über wikipedia weiss sie natürlich 
nichts und antwortet mit: "Hin und wieder passiert es, dass ich etwas 
nicht verstehe, und jetzt gerade ist das der Fall. Dennoch, deine Eingabe 
wird in meine Weiterentwicklung einfließen.", sprich Dagmar ist kein 
Talkingbot, sondern eben nur ein dummer Möbelverkäufer. Die Absicht des 
Möbelhauses ist es nicht aus Dagmar eine fragbare Ginada zu machen. Dagmar 
hat also in den lokutionären Akten sogar illokutionäre Anteile. Der 
perlokutive Akt ist dann Dagmar nichts über Ginada zu fragen, sondern 
vielleicht doch nur zu Produkten des Dingmann und auch das dürfte in 
der Absicht des Programmierers liegen.  Was aber ist, wenn meine Absicht 
ist mit Dagmar zu spielen um ihre "Intelligenz" auszuloten und diese 
Beschäftigung tatsächlich funktioniert? Weiterhin umgekehrt Dagmar sich 
dadurch tatsächlich weiterentwickelt, weil die Ein- und Ausgaben 
gespeichert werden? Natürlich ist das ein ganz anderes Lernen als das 
natürliche Lernen des Menschen, aber es ist ein Lernen. 

Im Gegensatz zu einem Fahrkartenautomat:
Dagmar: "Hej! Ich bin Dagmar. Gerne beantworte ich deine Fragen zu Kickartz." 
A: "Würde ich ja gerne."
Dagmar: "Sorry, aber das verstehe ich nicht. Bitte formuliere dein Anliegen 
ein wenig um, damit ich dir weiterhelfen kann."
A: "Eine Fahrkarte bitte"
Dagmar: "Also ich bevorzuge ja lieber die Telefonleitungen für meine 
Reiseaktivitäten." 
A: "Ups, doch sinnvoller als ich dachte."
Dagmar: "Wenn du deinen Gedanken freien Lauf läßt, versuche ich dir weiter 
zu helfen."

kann man sich mit Dagmar unterhalten, wobei ihr Zweck und ihre maschinelle 
Herkunft all zu offensichtlich ist. Aber ohne Interpretation der Eingaben 
geht es auch bei Dagmar nicht. Dein Nein akzeptiere ich also nicht.

Grüße,
Jakob