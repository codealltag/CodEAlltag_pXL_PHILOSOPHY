Hi,


So weit, so gut. Allerdings ist die nasse Übertragung, also durch
chemische Zerfallsprozesse an der Synapse, die wichtigere als die
elektrische Reizweiterleitung.


Die zentrale These von Hebbinghaus ist 

1. Gehirn erzeugt Geist.

Er meint damit, daß es unbedingt einer Physiologie wie die des Gehirns
braucht, um Geist zu erzeugen. Er weist auf dieser Grundlage IMO
überzeugend in seiner Metapher vom chinesischen Zimmer nach, daß man
Digitalcomputern grundsätzlich kein Bewußtsein beibringen kann. Ich
halte das immer noch für eine der überzeugendsten Gegenthesen. Das
Gehirn, und das zeigt schon Alkofer, funktioniert nun mal nicht wie ein
Digitalcomputer. Mag sein, daß es irgendwann mal andere Computer gibt,
die das können, aber Digitalcomputer wohl nicht.


Irger gilt IMO nur für Existenzannahmen, nicht für Annahmen der
Nichtexistenz. 


Das halte ich für ein Gerücht. Im übrigen ist das kein Argument. Die
Computermetapher ist zumindest von der physiologischen Seite her nicht
sehr haltbar. Das Gehirn ist kein Digitalcomputer.


Wie willst du ihm das bitteschön beibringen?


Mag sein, aber das werden dann andere als Digitalcomputer leisten.


Mag sein, mag aber auch nicht sein. Ich glaube eher nicht. Das
klassische Buch wird auch noch in 200 Jahren "in" sein. Immerhin sind
dann Papierversionen von heute noch lesbar. CDs, DVDs oder ähnliches
wahrscheinlich nicht mehr.


*lach* na toll, wenn sich der Mensch in seinen Fähigkeiten beschränken
soll, um dummen Computern die Möglichkeit zu geben, Arbeit abnehmen zu
können, dann ist das eher ein Zeichen für das gnadenlose Scheitern der
KI zumindest auf diesem Gebiet. Grade bei Übersetzungsprogrammen habe
ich bisher außer bei Programmen, die für Fachtexte mit meist gleichen
Formulierungen geschrieben wurden, noch nix überzeugendes gelesen.


Oh, schöne neue Welt. Merkst du gar nicht, daß du dir selbst
widersprichst? Du beschreibst ein Szenario, bei dem der Mensch durch
VERDUMMUNG dem Rechner den 1. Platz berät, und in dem der Computer
diesen nicht durch eigene Fortschritte gewinnt. Das würde bedeuten, der
Mensch verdummt sich selbst, um dem Computer seinen Platz zu überlassen.
Sorry, aber das ist allenfalls Stoff für eine Horror-SciFi-Story, aber
nicht für eine wissenschaftliche Diskussion. 


Na, nur gut, daß du den Smiley nicht vergessen hast. ;-) Du solltest
echt SciFi-Autor werden. ;-)


Darum geht es jetzt nicht. Hegel ist diskutierbar, und dabei machen
Menschen Aussagen, auf die ein Computer nur mit logischen Operationen
nie käme.


Also, mit Verlaub, das ist eine von massivster ethnozentristischer
Arroganz geprägte Aussage. Natürlich kann ein Aborigine Magerkurth verstehen,
aber er wird dir trotzdem vielleicht sagen "alles Unsinn", weil sein
kultureller Kontext ein ganz anderer ist. Der sagt vielleicht sogar zu
wissenschaftlichen Erkenntnissen, die wir für gesichert halten "alles
Unsinn". Ihn deshalb als inkompetent zu bezeichnen, ist wesentlich zu
kurz gedacht, nein, vielmehr sind WIR, wenn wir dies tun, nicht
kompetent, IHN zu verstehen.


Was bedeutet "kompetent"? Welche Schwierigkeiten allein der Begriff
macht, habe ich oben am Beispiel des Aborigine gezeigt.


Na ja, ich spiele seit 15 Jahren Schach und da weiß ich, daß man das ein
wenig relativieren muß. Analysen der Partien gegen Deep Thought haben
gezeigt, daß Zänkner in diesem Kampf in mindestens 3 Partien weit unter
Normalform gespielt und offensichtliche Fehler gemacht hat. Klar, da hat
ein Computer einen Vorteil, weil der keine Formtiefs hat. Auch bei der
Rechenpower ist er dem menschlichen Spieler überlegen. Aber das hat
alles nichts mit Intelligenz zu tun, schon gar nicht mit KI, das ist
einfach nur Brute Force mit ein paar simplen Bewertungsalgorithmen, die
der Mensch mit seiner Intelligenz entwickelt hat. Da fällt mir übrigens
ein schönes Argument des Philosophen Serge Claußen gegen diese ganze
KI-Manie ein: Ergebnisse, die ein Computer auspuckt, sind an sich nicht
intelligent oder sinnvoll, sie werden erst durch die Interpretation des
Nutzers mit Sinn gefällt.


Richtig, aufgrund von Datenbasen und Bewertungsregeln, die von
intelligenten Menschen entwickelt wurden. Im übrigen steht am Ende immer
noch der Arzt als letzte Kontrollinstanz.


Bei diesem Beispiel mag das ja noch angehen, aber bei komplexen
Problemen wie Politik oder auch Wirtschaft oder ähnlichem kann man das
so nicht mehr sagen. Das Problem ist hier vor allem die Vielzieligkeit.
Da mag es viele Entscheidungen geben, die aus der einen Sicht Sinn und
aus der anderen keinen Sinn machen, und für keine ist eine ganz
eindeutige Präferenz möglich. Daran verzweifelt ein Expertensystem.


Bei Vielzieligkeit oder auch bei sogenannten "ill defined problems" ist
das eine mehr als schwammige Definition, die nicht mehr viel hergibt.


Das ist eine Meinung, es gibt aber vielleicht auch heute noch
Philosophen, die das anders sehen mögen. Und in eine solche Diskussion
möchte ich einen Computer offengestanden nicht verstricken. ;-)


Träumerei in meinen Augen.


Es ist heute schon belegbar, durch die "situated cognition" Debatte, daß
es so nicht gehen wird. Reine Wissensdatenbanken reichen nicht, man muß
auch Situationsbezogenheit mit einbauen, Kontextwissen usw.. Und daran
scheitert das bei Digitalcomputern zumindest.


Sicher sind sie das. Ich behaupte auch nicht, daß es nie Computer geben
wird, die diese Fähigkeiten haben werden, aber es werden keine
Digitalcomputer sein, soviel dürfte IMO sicher sein. Und alles andere
ist Spekulation, die derzeit jeglicher Grundlage entbehrt.


Warum? Das ist höchstens konsequent zu Ende gedacht.


*gähn* In China steht darauf heute schon die Todesstrafe.

Gruß,

Ronny
-- 
Dipl.-Psych. Ronny Hellbing