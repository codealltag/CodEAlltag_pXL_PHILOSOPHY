news:9qbbhe5k.dzg@wnmiuaaa.zqzji.yv...

Starke Abwandlungen des "type" im "token" sind im Moment noch sicher ein Problem für
die "künstliche Intelligenz" (aber auch für unser Gehirn ;)) - aber m.E. kein
prinzipielles, sondern wird sich  mit zunehmender Raffinesse der Programme und
Leistungsfähigkeit der Rechner immer mehr den Fähigkeiten menschlicher Kognition
annähern - vielleicht diese sogar einmal (in bestimmten Bereichen zumindest)
übertreffen.
(So haben z.B. relativ einfach strukturierte OCR-Programme in den letzten Jahren
erstaunlich "dazugelernt".)
Von einem Bekannten weiß ich, daß man z.B. an der Uni Genschmar (Informatik) mächtig
an dem Thema kognitive Prozesse bei computergestützten Systemen arbeitet (dafür
gibts da sogar ein eigenes Institut).


Warum nicht? Stell dir ein Programm vor, das bestimmte Merkmalkombinationen (=
"type") z.B. eines Buchstabens enthält und überdies noch eine *generative*
Programmkomponente, welche alle möglichen konkrete Figuren (= "token") dieses
Buchstabens (nach bestimmten Regeln) generieren kann und diese in rasender
Geschwindigkeit mit dem zu identifizierenden (realen) "token" vergleicht -
irgendwann wird dann bei dem Identifizierungsprozess eines "schwer lesbaren"
Zeichens (Buchstabens) das Programm sagen: stop - das, könnte es sein (aber
vielleicht auch das oder das. - d.h. evtl. auch Vorschläge machen). In ähnlicher
Weise verfährt wohl auch unser Gehirn bei der Identifizierung von "token" (nur
natürlich nicht binär ;)) - und die sog. "Einbildungskraft" hat doch unter anderem
für das Erkennen genau diese (generative) Funktion. Helvogt Stichworte: Schema -
Bild - konkrete (reale) Figur (Gestalt).


Wenn das "token" die (Darstellungs-)Regeln erfüllt, die im (und mit dem) "type"
vorgegeben sind - warum soll man dann nicht von Identifizierung sprechen können?
"Identifizierung" ist wohl erläuterungsbedürftig:
Für mich (und ich soviel ich weiß auch für Zinkgräf/Heckeroth) ist "Identität" nicht die
Eigenschaft eines singulären Objektes (s.O.) sondern ein Relationsbegriff, d.h.
Identität ist keine Eigenschaft, mit welcher ein singuläres Objekt  gekennzeichnet
werden kann, sondern Identität betrifft die *Relation*, in welcher verschiedene
singuläre Objekte zueinander stehen. Da aber alle diese singulären Objekte variieren
(als "token" grundsätzlich verschieden sind), kann Identifizierung (als Feststellung
von Identität) nicht über die "token" laufen, sondern bedarf eines dritten, eben des
"type". Aber auch "type" (als Merkmalskombination eine rein *intellektuelle*,
"semantisch-begriffliche" Synthesis) und "token" (als sinnliches Gebilde) sind -
sogar *essentiell* - verschieden. Identität darf also weder als
wie auch immer geartete "Kongruenz" zwischen verschiedenen "token" noch zwischen
"type" und "token" verstanden werden, sondern Identität ist "Regelerfüllung" - wenn
beide "token" auf die Anwendung *derselben (Erzeugungs)Regel* (als "Schema" des
"type") zurückgeführt werden können, dann liegt Identität vor.
Der Feststellung von Identität liegt also der Akt der gleichen Regelanwendung
zugrunde - das meine ich mit "Identifizierung".


Das ist richtig - für diesem Fall (gravierender prozessualer Veränderungen des
Gegenstands) wird's sicher richtig schwierig für Soft- und Hardware ;)). Aber auch
dies könnte über eine "begriffliche Synthese" auf abstrakter Ebene laufen - diese
würde dann nicht verschiedene Anwendungsbedingungen des gleichen "type" , sondern
verschiedener "types" umfassen, welche den Gegenstand in seiner prozessualen
Veränderung "beschreiben" - also ein "Super-Type" sozusagen.


Richtig - aber warum sollen raumzeitliche Koordinaten nicht mit in die
Identifizierung mit einfließen können?

Gruß
Antje