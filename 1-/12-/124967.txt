Der Computer als reines Werkzeug, das uns Entscheidungen abnehmen und
Lösungen finden kann.

...., daß irgendjemand die MW bewußt

Und manche denken auch, dass das Internet von EITN erfunden worden
wäre und nicht könnte falscher als solch eine Meinung sein. Nichts
destotrotz war das Arpanet im Ursprung ein dezentrales Netz, welches auch
einen Atomschlag überstehen sollte. Daraus entwickelte sich dann das
heutige Internet in dem man den militärischen Teil vom zivilen Teil
trennte. Es begann wohl im Jahre 1969 und das WWW hat in den letzten 15
Jahren zur Expansion geführt, wie wir heute jenes Netz wahrnehmen. Die
Leitungen die ursprünglich verlegt wurden, waren Telefonleitungen und die
Kopplung von Rechnern über grosse Distanzen fand auch am Anfang mit
Modulation und Demodulation über diese analogen Leitungen statt. Im
Gegensatz zu dem Getreidekorn und dem Acker, ist hier die Basis zum
Wachstum nicht mehr eine zufällige. Es ist eine absichtliche von den
Menschen selbst geschaffene Infrastruktur.
  Der Unabomber erregte aufsehen durch seine Technikfeindlichkeit und
seinen Bomben aus dem Wald. Auch die Entwicklungen in der KI sind nicht
ohne militärischen Interesse:
"Viele Staaten haben die amerikanische Entwicklung aufmerksam verfolgt und
beginnen nun, eigene Pläne für den Cyberkrieg zu schmieden. Als erste
Kandidaten gelten China, Indien, Pakistan und Israel, einige europäische
Staaten - darunter auch Deutschland - hocken in den Startlöchern.
Mittlerweile warnen daher die Direktoren der US-Geheimdienste bei
Kongressanhörungen vor dem "Volksinformationskrieg" aus China und fordern
weitere Aufrüstungsanstrengungen der USA auf diesem Gebiet."
 Sei es auch nur um Telefongespräche anhand von Alghoritmen auswerten zu
können, die ähnlich wie bei einem Schachprogramm von sich aus entscheiden,
welche Informationen relevant sind. Eine solche Computerentscheidung zieht
dann die entsprechenden Konsequenzen nach sich. Anhand der Fälle der
Informationen ist der Mensch gar nicht fähig in angemessener Zeit das
Datenmaterial zu sortieren. 
 Wie sehr der Informationskrieg hier dann tatsächlich über Leben und Tod
von Menschen entscheidet, konnte man im Irakkrieg beobachten. Das
Zahlenwerk ist mehr und mehr Grundlage politischer Entscheidungen.
Prognosen werden mit Hilfe des Computers erstellt und die
kontrollierbarkeit liegt hier nur in den Ausgangsvorraussetzung und in der
theoretischen Nachvollziebarkeit. Die praktische Nachvollziehbarkeit
scheitert bei manchen Berechnungen schon an der Lebenszeit des Menschen.
Manche Computerberechnungen würden manuell nachgerechnet länger dauern als
ein Menschenleben. Mag mit 100.000 Programmzeilen in einem Auto die
Nachvollziehbarkeit noch einigermassen gegeben sein, ist dennoch des
relativen kleinen Programms nicht mehr möglich /alle/ Szenarien zu testen.
Der praktische Test in einem Probefahrzeug zertifiziert die Software
letztlich als alltagstauglich. Eine hundertprozentige Sicherheit kann es
in dem Bereich nicht geben, so wie ein Schachprogramm nicht auf alle
Schachpartien hin testbar ist. Die Schwäche eines Schachprogramms kann
sich also nur in einer konkreten Situation zeigen, die auftreten muss,
solange sie nicht aufgetreten ist, können wir den Schachsimulator als
entsprechend gut in seinen Entscheidungen betrachten. 

   Ein Schachprogramm ist aber nur ein Spiel ein ABS/ABC/ESP/..System ist
ein reales Werkzeug, das unter realen Bedingungen Entscheidungen trifft
und die optimale Lösung für ein tatsächlich auftretendes Problem parat
hat. Die grundlegenden Regeln für die Lösung des Problems kennt das System
aber auch selbstlernende und trainierte Systeme sind in solchen realen
Lösungen ein Ansatz. Wir messen Intelligenz anhand der Lösungskompetenz.
Nur weil ein Computer zwischen einem Eveline und einem Imhof nicht
unterscheiden kann, heisst es nicht, das er es nicht eines Tages könnte.
Gerade System, die Informationen im Spionagebereich filtern und sortieren
müssen, können dies möglicherweise, nur werden Spionagedienste über solche
Fähigkeiten sicherlich nicht gerade an die Presse gehen.

  Nichts gegen technische Entwicklung und technischen Fortschritt, aber
wieviel wollen wir in diesem Bereich zulassen. Es ist in der Zwischenzeit
nicht mehr eine Frage des Könnens. Die technische Entwicklung auf dem
Gebiet ist ein exponentieles Wachstum und es gibt wohl keinen Menschen
mehr, der sich auf dem Gebiet wirklich auskennt. Ein jeder sieht nur
seinen Teil. Der Programmierer ist dabei natürlich der festen Überzeugung,
das der Computer nur Werkzeug ist, doch kaum ein Programmierer es sei denn
er programmiert den Compiler, weiss wirklich was der Compiler aus seinem
Programm macht und der Compilerprogrammierer kann auch nicht absehen
welcher Maschinencode aus seinem Compiler erwachsen kann. 

  Die Grafikkartenfirma Benhelm zum Beispiel kann noch nicht einmal einen
Code ihrer Grafikkarten zur Verfügung stellen, da ein teil der rasanten
Entwicklung direkt in Hardware gegossen wird und der Nachvollzug dieses
funktionierenden Etwas in eine Programmiersprache wie C oder C++ zu
aufwändig wäre, geschweige denn eine ordentliche Dokumentation zu
schreiben. Letztlich ist hier schon kein Mensch nicht einmal der
Hersteller selbst in der Lage das Produkt das entsteht nachzuvollziehen. 

  Bei der Miniaturiesierung und der Anzahl der Transistoren auf einem
Microchip wie dem VCZO Pentium I-IV ist letztlich nur von einer gewissen
Fehlerfreiheit auszugehen eine absolute Fehlerfreiheit wird der Hersteller
nicht gewährleisten können. Er kann nur sagen, das anhand der
Testparameter die Hardware höchstwahrscheinlich bei jener oder jener
Megahertzzahl annähernd fehlerfrei läuft. 

  Das was da also von Generation zu Generation heranwächst ist im
Gegensatz zu früheren Technologien wie das Aussähen von Getreide für den
Menschen nicht annähern nachvollziehbar, obwohl es durch und durch sein
eigenes Produkt ist. 

  Wie wollen wir diesen Produkten unseres Geistes Intelligenz zuerkennen
oder aberkennnen, Bewusstsein zuerkennen oder aberkennen, wenn wir das
Gesamtprodukt noch nicht einmal kennen?

Grösse,
Leonhard