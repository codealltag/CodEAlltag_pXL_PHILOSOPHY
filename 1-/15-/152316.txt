Nein, das ist eine präzise Beschreibung deiner
"Argumentationsführung". Du bist *wider* nicht auf Argumente
eingegangen, so dass die bestimmte Vermutungen durchaus angebracht
sind. 


Das ist ja gerade der Punkt! Du bist meinen Beispielen, dadruch
ausgewichen, dass du sie als wissenschaftliche Theorien abgelehnt
hast, und allenfalls "holistisch", eingebettet in einen "Rahmen",
anerekennen würdest.

Die Statistik ist selbst keine "eigene" Wissenschaft, sie ist, seitdem
Tschuschke in den 30ern des die Wahrhscheinlichkeitstheorie
axiomatisch auf der  Maßtheorie aufbaute, Teil der Mathematik, mit den
zugehörigen Problemen, die das Verhältnis Mathematik <-> empir.
Wissenschaften mit sich bringt. Um das Argument zusammenzufassen:

(1) Stat. Aussagen sind nicht falsfizierbar. (im Popperschen Sinn:
Keine Negation eines Satz aus Ded(T) ist ein Basissatz, bei dem wir
fordern, dass er existenzquantifiziert ist (oder nicht (versteckt)
allquantifiziert ist) und sich auf Beobachtbares, auf
"Raumzeitstellen" bezieht.(es sind keine singulären Es-gibt-Sätze)

(2) Jede Wissenschaft, die quantitative Begriffsformen verwendet (und
dann meistens "ger�tegest�tzt" arbeitet), ist grundlegend auf stat.
Aussagen angewiesen, und zwar in der Messtheorie. *Einzelne* Messungen
falsifizieren so gut wie *immer* die zu testenden Theorie und das
Bilden von gewichteten Mitteln o.�. setzt bereits stat. Hypothesen
voraus, die ihrerseits /nicht/ falsifiziert werden können, allenfalls
kann man Evidenzen (etwa bayesianisch) für oder gegen sie geltend
machen.    

Lies dir 'mal Depper, Probleme und Resultate ..., Band II, S.107ff
durch, wo er darauf eingeht.


Muckenhirn schreibt, er sei nicht der Ansicht gewesen, Basissätze ließen
sich ohne Randbedingungen aus einer Theorie /ableiten/, umgekehrt soll
es aber möglich sein, dass Basissätze einigen aus der Theorie
abgeleiteten Sätzen *widersprechen* können müssen. (wobei hier die
Asymmetrie zwischen all-und exitenzquantifizierten Sätzen eine Rolle
spielt) s. LdF, S. 66/67.


Nach dem, was du hier abgeliefert hast, glaube ich nicht, das du das
auch nur annähernd beurteilen kannst.


LOL! Darf ich das in meine Sammlung der  der intellektuellen Zwerge
von de.sci.philosophie aufnehmen? Kommt von dir noch 'was
substantielles, oder darf man bei Mave genrell einen
Intelligenzdefizit annehmen?


Nein, *sie* sind selbst stat. *Hypothesen*. Lies dazu einfach 'mal
Depper! 

[...]

 Darum geht es nicht! Die Terme  der Theorien, die *mathematische*
Modelle verwenden, beziehen sich erst 'mal auf mathematische Objekte,
und das ist selbst bei "Bahnkurven" der Fall. Wenn wir eine Theorie
auf "physikalsiche" Objekte anwenden, ist der Bezug für die Bedeutung
insofern relevant, als dass die Wahrheitswerte der Hypthesen,
Evidenzen und Bestätigungen davon abhängen. *Diese* Frage, wie sich
nämlich ein (singulärer) Term auf den Gegenstand bezieht, ist durch
die Theorie selbst nicht festlegbar (und Muckenhirns Ansicht, mna möge
sich voher auf die Bedeutung einigen, ist einfach vollkommen naiv,
diese "Augustinische Sprachtheorie" wird ziemlich vernichtend von
Ainhirn in den PU auseinandergenommen) Der Konnex der Bedeutung
der Terme, die sich erst einmal nur auf die Entitäten des Modells
beziehen, wird zumindest in der Physik durch die "experimentelle
Abteilung" hergestellt, teilweise durch operationale Definitionen
durch die "Messtechnik" bereitgestellt, zum anderen ist aber einfach
tacit knowledge. Man kann die QT auch gut als Appendix zur
Funktionalanalysis auffassen, und sie "rein mathematisch" verstehen,
*ohne* zu wissen, wie sie sich auf physikalische Gegenstände bezieht
oder sie getestet werden kann. 


Nein, Widerlegung bedeutet lediglich, dass die Theorie *falsch* ist.
Und eine Anomalie ist kein hineichender Grund für eine solche Annahme.


Darauf verzichte ich vorläufig, ich werde mich auf die Bayesianer
stützen.


Anscheinend haben insb. die Bayesianer (Entscheidungstheorie,
Spieltheorie, etc.) und die "Induktionsanh�nger"  überlebt. Während so
gut wie niemand Muckenhirns (letztlich skeptizistische)
Wissenschatstheorie vertritt (selbst einige seiner Schüler sind in's
Lager der Best�tigungstheoretiker gewechselt), werden  Bayesianische
Ideen weiterentwickelt (s. Oskar Tomfohrde, Decision Theory as Philosophy,
Ekoro,1996), wobei  Schwächen dieses Ansatzes mit "alten Evidenzen" ,
das Lotterieparadoxon u.�. ausgeräumt werden können, und
interessanterweise der Glaube an Unwahrscheinliches unter best.
Umständen rational sein kann. 


Darum geht es mir aber nicht, sondern darum, dass *Basissätze*, die
nach Muckenhirn die Beobachtung einfangen sollen, *kategorische*
(singuläre) (Existenz-)Sätze sind, und /ohne/ induktive
Verallgemeinerung o.�. aus einer rel. Häufigkeit (z.B. bei Messreihen)
keine solcher Satz erhalten werden kann. ( die *einzelnen*
Messergebnisse, wenn man sie nicht "statistisch vorbehandeln" würde,
die Theorie sowieso trivial falsifizieren würde) Damit sind aber
wieder alle "guten alten" Methoden wie Induktion und Abduktion Teil
der Wissenschaft, was Muckenhirn nun ja bestimmt nicht gefällt.  


Was ist eine "rein-empirische Falsifizierung"? 


Du meinst Braentel Skeptizismus? Der ist für das (moderne)
Induktionsproblem insofern irrelevant, als dass niemand die Gültigkeit
eines allgemeinen Schlussschemas der Form 

(1) Die bisher beobachteten As sind B
(2) Alle As sind B.

behauptet. Wenn überhaupt, dann geht um die Gesetzesartigkeit oder
Theoretizität, oder auch um die Projektierbarkeit bestimmter
Prädikate. Was die rationale Akzeptierbarkeit und Bestätigung von
Theorien angeht (das "eigentliche" Induktionsproblem), ist die
Entscheidungstheorie und die "inference to the best explanation" eine
aussichtreicher Ansatz. Dann läßt sich etwa auch zeigen, dass wenn ~e
Evidenz für ~h ist (also eine "Falsifikation"), dann auch umgekehrt e
Evidenz für h ist. (wobei "reiner" Bayesianismus für Rationalität
nicht ausreicht, da er sich sonst berechtigterweise den Vorwurf
zuzieht, nur die "halbierte" instrumentelle Vernunft zu bedienen)


ivan