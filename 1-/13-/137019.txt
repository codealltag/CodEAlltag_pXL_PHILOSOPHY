Hallo Valentino,
vielen Dank, daß Du geantwortet hast.

Valentino Haass wrote:

[...]


[...]


Ohhhh!


Ja. Allerdings sehe ich eine ganz wesentliche Schwierigkeit dieses 
Modelles: Ich werde weiter unten darauf zurückkommen. Ich bestreite 
nicht, daß Deine Argumente innerhalb des funktionalen Paradigmas in sich 
schlüssig sind. - Ich frage mich allerdings, ob man damit wirklich dem 
Verständnis davon näher kommt, was es denn nun mit Qualia und/oder 
mentalen Zuständen auf sich hat.


Die Frage ist hier, was System heißen soll. Ich meine nicht hinsichtlich 
der oben gegebenen Definition, die ist ja so akzeptabel; sondern in 
Bezug auf hier verhandeltes Problem des *Selbstverständnisses* des 
Systems. Weiter unten gibst Du ja eine "Illustration" mit dem 
Roboterbeispiel. Nur: Dein Roboter muß, um zu eine "Systemreaktion" zu 
kommen, *glauben*, daß er Schmerz habe. Ich möchte nun nicht darüber 
diskutieren, ob er "glauben" oder nicht besser "wissen" muß; ich würde 
aber gerne mal näher erläutert haben, was es - im funktionalistischen 
Paradigma - *bedeutet*, wenn jemand etwas "glaubt" oder "weiß". Worauf 
rekurriert er dabei, etwa, wenn er sagt, er habe Schmerzen?

Meiner Ansicht nach ist das "kausale Netz" im Gesamtzusammenhang des 
Systemes nämlich das eigentliche Problem. Der Funktionalismus neigt - 
etwa in Fragen der Schmerzdiskussion - zu einer Übervereinfachung, die 
ich mit Bezug auf das Phänomen Schmerz grob so umreißen möchte: Es gibt 
so etwas wie einen Kausalnexus zwischen neuronalen/allgemein-physischen 
Status und mentalen Zuständen (die so etwas "bewußt machen"). Ersteres 
ist elementar, zweiteres ein Epiphänomen.
Der Punkt ist aber, daß hier bereits zur *Voraussetzung* der Diskussion 
gemacht wird, was eigentlich erst die Verhandlung erbringen sollte. Und 
deshalb drehen sich etwa auch unsere Diskussionen um diese Fragen im 
Kreise. Denn einmal ganz simpel betrachtet ist's doch so, daß wir das 
gar nicht wissen!


Ich bin anderer Auffassung. Mitnichten würde ich sagen, daß ich eine 
Suppe "erkannt" haben muß, um sie auszuspucken. - Nehmen wir hier der 
Einfachheit halber den Ekel: Ekel als mentaler (und präreflexiver) 
Zustand setzt keineswegs voraus, daß ich wissen muß, *weshalb* es mich 
ekelt (ich muß ja noch nicht mal wissen, daß das, was mich da ergreift, 
"Ekel" heißt). Sondern ich ekele mich einfach. Da es die versalzene 
Suppe war, die den Ekel hervorrief, fügt dem Bewußtseinsdatum (dem 
Erleben des Ekels) rein gar nichts hinzu. Sondern das tut erst die 
Reflexion: "Aha, ich habe mich geekelt, weil die Suppe versalzen war." - 
In diesem Satz thematisiere ich zuförderst *mein* Erleben des Ekels, 
also den (mentalen) Zustand, im Ekel (gewesen) zu sein; und erst dann 
beziehe ich den Ekel auf ein Objekt. Das bedeutet hinsichtlich meiner 
oben angedeuteten Bedenken gegenüber dem Funktionalismus: Die 
Herstellung der kausalen Beziehungen ist das *Ergebnis* der Reflexion 
auf einen selbst präreflexiven Zustand. - Wir hatten das ja schon des 
öfteren: Der Punkt ist, daß ich mich, betrachte ich das Ganze in 
erkenntnistheoretischer Hinsichtnahme, sehr wohl täuschen könnte, was 
die Konstruktion der Kausalkette betrifft. Ich kann mich aber unmöglich 
darin täuschen, mich geekelt zu haben.
Mein Vorwurf an den Funktionalismus ist mithin folgender: Er läßt die 
Bedingung der Möglichkeit, überhaupt (via Reflexion) so etwas wie 
kausale Gefüge in einem Systemzusammenhang postulieren zu können, unter 
den Tisch fallen und setzt stattdessen die der Reflexion abgewonnene 
Kausalbeziehung als das Erste. Der Witz ist aber, daß man die kausale 
Relation nur über eine Reflexion erhält. Und nun frage ich mich, wer 
oder was im Funktionalismus worauf reflektiert, um solche kausalen Nexus 
überhaupt postulieren zu können. Ich habe den Eindruck, daß diese Frage 
einfach ausgeblendet wird, weil ihre Beantwortung den vorher 
herbeigezauberten axiomatischen Hintergrund ad absurdum führen würde. 
Eben gerade so, wie Dein Roboterbeispiel an sich absurd ist, weil Du 
Dich dabei einiger für den Menschen reservierter Begriffe und 
Beschreibungen (und mentaler und reflexiver Zustände) bedienen mußt, um 
überhaupt ausdrücken zu können, was Du ausdrücken möchtest: angesichts 
dessen frage ich mich dann immer (wie auch in mancherlei KI-Diskussion), 
warum überhaupt solche Beispiele gebracht werden: Wenn einem Roboter 
oder Computer (und noch dazu rein hypothetisch) all jene Dinge 
zugeschanzt werden, die wir ansonsten nur beim Menschen finden, ist's 
doch klar, daß ich dann eine tolle funktionalistische Show abziehen 
kann. Es bleibt nur zu fragen, was es heißen - und bedeuten - soll, wenn 
man sagt, ein Computer oder ein Roboter *glaube*, *denke*, *fühle* usw. 
usf..
An mich ist schon manches Mal die Anforderung ergangen, ich solle mir 
doch gefälligst mal vorstellen, irgendeine blöde Maschine denke oder 
glaube irgendwas. Nur: um mir das vorzustellen, brauch ich eben gar 
keine Maschine, das kann ich ja mit Bezug auf das Objekt Mensch tun! - 
Und dabei gibt's Probleme genug (wie wir doch wohl beide wissen ;-)). 
Ich muß mir absolut keine Gedanken darum machen, was irgendwelche 
Roboter oder Turingmaschinen rein theoretisch alles machen könnten, um 
mir dann sagen lassen zu müssen, "sieh', das läßt sich alles ganz 
wunderbar funktional erklären, wir brauchen keine Philosophie des 
Bewußtseins mehr!" Pustekuchen! Kein Schwein hat bisher zeigen können, 
daß eine Maschine irgendwas zu glauben imstande ist (ich frage mich 
übrigens, wie das gehen sollte ;-)). Aber allerorten werden mächtig 
gewaltige Anleihen auf dieses Hirngespinnst gemacht ...

[...]


Ja. Aber siehe oben: Ich halte das für ein Postulat, dem es - bei 
genauerem Hinschauen - mehr darum geht, das eigentliche Problem 
wegzureden, als es zu lösen.

Letztendlich vertrete ich selbst ja auch ein funktionalistisches 
Paradigma: für mich sind mentale Zustände nämlich (ganz im Gegensatz zu 
dem, was Du mir vielleicht unterstellen magst) insofern funktional, als 
sie die Voraussetzungen für Handlungsstrategien bilden, die nicht mehr 
vorhandene oder wertlos gewordene Reiz-Reaktionsschemata bzw. instinktiv 
gesteuerte Verhaltensweisen kompensieren.
Nehmen wir ein griffiges Beispiel ;-): Es ist - jedenfalls in weiten 
Teilen der menschlichen Zivilistation - nicht unbedingt üblich, die 
plötzlich auftretende und manchmal vielleicht auch sehr starke Regung 
des Sexualtriebes unmittelbar auszuagieren. Schaue ich mir etwa Löwen 
oder Affen an, so sieht das ja auch handgreiflicherweise ganz anders 
aus. Aber wie kommt das? Nun, vielleicht, weil wir die Fähigkeit haben, 
zwischen das Erleben der unmittelbaren Triebäußerung (als zunächst 
präreflexiv vorliegendes Datum des Bewußtseins) und deren Ausagieren die 
Reflexion zu schieben, z.B., indem wir uns die Folgen möglicher 
Triebhandlungen entwickeln.
Ich halte das für ein evolutionär entwickeltes Schema, dessen 
funktionale Komponente m.E. nicht zu unterschätzen ist. Die Tatsache, 
daß gewöhnlicherweise beim Mann solche Begebenheiten von einer heftigen 
Testosteronausschüttung begleitet sind, spricht für eine Korrelation 
gewisser biochemischer Vorgänge und mentaler Zustände (die ich auch 
keineswegs bestreite); aber ich fühle/erlebe eben gelegentlich solcher 
Zustände nicht meinen Testosteronspiegel steigen, sondern ... ehm ... ja 
... also ... ;-)

Hier kommt dann Illenseer in's Spiel und da hat er m.E. eine bis heute 
ungebrochene Relevanz!
Es wäre - anbei dieser kleinen Entwicklung sei dies bemerkt - ja auch 
reichlich kindisch, würden irgendwelche Hirnstromakrobaten und 
Hormonfetischisten daherkommen und behaupten, Herr H läge, wenn er sage, 
er sei gerade "rattenscharf"; denn sie könnten anhand unwiderlegbarer 
Beweise (in Form aller möglichen Hormon- und Hirnstromkurven) definitiv 
ausschließen, daß er überhaupt "rattenscharf" sein könne!


Natürlich setze ich die voraus! Aber das eben gebrachte Beispiel mit 
Herrn H läßt ja auch gar keine andere Möglichkeit zu. Und wie gesagt: 
geh' her und widerlege Illenseer.
Außerdem läßt sich - wie ich schon oben angedeutet habe - dieser Spieß 
ja auch umdrehen: Der Funktionalismus setzt eben die Identität beider 
voraus. - Und bleibt den Nachweis dafür schuldig.


Valentino, mich interessiert die "Freiheit des Willens" nur marginal. Ich 
sehe mich hier eher dem schönen programmatischen Ansatz Holschneider 
verpflichtet, daß man auf die Phänomene schauen soll, so wie sie 
vorliegen - und vor allem: ohne schon allzusehr theorielastig an sie 
ranzugehen (ich weiß natürlich, daß das ein nie zu erreichendes Ideal 
ist, aber letztlich geht's mir in diesem Bereich tatsächlich um eine 
phänomenologische Analyse).


Den Substanzdualismus, etwa descartscher Provenienz - hat prinzipiell 
schon Frühauf überholt. Lies Dir doch bitte mal den letzten Abschnitt in 
Illenseers Aufsatz, so, wie er im Pietro-Reader präsentiert wird, durch, 
dann verstehst Du vielleicht, daß es mir hier nicht um 
Prinzipienreiterei geht. Und auch nicht um Fragen, die ich - jedenfalls 
absehbar - sowieso nicht lösen kann; sondern darum, für ein bestimmtes 
Phänomen eine möglichst integre Erklärung (und vielleicht sogar etwas 
Verständnis) zu erreichen.
Ich maße mir keinesfalls an, das sog. Leib-Seele-Problem und die mit 
meiner Position verbundenen ontologischen Probleme im Griff zu haben. 
Ich kann aber - trotz dieses Mankos - auch nicht so tun, als ginge mich 
das nichts an; und genausowenig kann ich hergehen und nun mal geschwind 
zum Funktionalisten mutieren, nur, weil ich mit meiner Position vor 
ontologischen Problemen stehe, die ich nicht lösen kann. Zumal ja der 
Funktionalismus und andere monistische Konzepte selbst nur *wähnen*, 
damit keine Probleme zu haben. Wegschwallerei ist nicht gleich Auflösung 
des Problemes; auch dann nicht, wenn's grad' modern ist, diesem Glauben 
zu frönen ...


Ach Valentino! Was soll denn das heißen? Schmerzen zu *spüren* ist doch 
etwas genuin Phänomenales. Was - um alles in der Welt - soll denn 
bitteschön ein "funktionales *Spüren* von Schmerzen" (!) sein? Meinst Du 
nicht, daß Du hier genau in jenen - ich möchte fast sagen: 
sprachzauberischen - Bereichen zu fischen anhebst, wo Du genau 
betrachtet doch immer nur einen faulen Fisch an der Angel haben kannst? ;-)


Gar nicht, weil das Beispiel auf nichts Vernünftiges hinausläuft. S.o.! 
- Was soll das heißen, daß ein Roboter "glaubt, daß ..."?

Das, was Du mit dem Beispiel gerne zeigen möchtest, liefert es nicht, 
weil Du hier in Wahrheit gar keinen Unterschied zwischen Robotern und 
Menschen mehr machst (indem Du nämlich unterstellst, der Mensch 
funktioniere so, wie man das anhand eines Roboters simulieren könnte und 
indem Du Roboter anthropologisierst: beides sind aber nur Wunschträume; 
nichts davon kann auch nur im Entferntesten als real angesehen werden). 
- Wozu also soll das Beispiel gut sein?


Ich versuche zu unterscheiden! Aber da kommt trotzdem nichts bei raus, 
was etwas zum Problem beitragen könnte!
Sag' mir doch bitte mal, ob, unterstellt, der Funktionalismus habe 
Recht, ein Schmerzunempfindlicher wissen könne, was es bedeutet, 
Schmerzen zu haben.


Mit freundlichen Größen


Severin