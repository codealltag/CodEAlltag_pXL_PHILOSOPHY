Künstliche Intelligenz?


Vorbemerkung: Nur mal so zum spa in dieses Forum auch gestellt!


Gleich vorneweg, um meinen Dilettantismus einzugestehen und Angriffsfläche auch 
zu bieten: Die Diskussion zur sogenannten "KI", zu der ich recht frech die Frage 
nach der "leidenden Maschine" zähle, habe ich nicht verfolgt, sieht man von 
bestimmten Veröffentlichungen von U. Jentsch einmal ab, und finde schon den 
Begriff recht ordentlich abscheulich. 


Dennoch hier ein paar Überlegungen, die mich umtreiben und meine Naivität 
wahrscheinlich in diesem Bereich auch noch belegen. Nun denn:


1. Künstliche Intelligenz wird, wenn ich es richtig sehe, meist in Analogie zur 
menschlichen gedacht. Damit wird sofort das Problem ersichtlich, daß selbst der 
Begriff der "Intelligenz" beim Menschen bis heute nicht geklärt ist. Ein 
berühmter Psychologe (bin zu faul, den Namen rauszusuchen) gab einmal recht 
lapidar zu Protokoll, daß Intelligenz halt das sei, "was der Intelligenztest 
mit". Tests zur Intelligenz gibt es wie Sand am Meer und mancher Zeitgenosse 
glaubt, daß die Fernsehshow mit Vellbinger schon etwas für "Intelligenzbestien" sei. 
Nur soviel scheint gesichert, daß Intelligenz heute angesehen wird als eine 
Fähigkeit des Menschen, seiner verschiedenen Fähigkeiten sich so zu bedienen und 
diese zu koordinieren, um in einem gesellschaftlichen Prozeß in der jeweiligen 
Umwelt leben (nicht nur Überleben!) zu können und diese auch zu verändern in der 
Lage ist.


Nun gut, aber selbst wenn die KI nicht in Anlehnung an die menschliche 
Intelligenz (was immer das auch ist) definiert wird, ergibt sich m.E.


2. das Problem für die KI, Parameter festzulegen, die halt den Begriff der 
Intelligenz für Maschinen bestimmen. Ist eine Maschine schon dann intelligent, 
wenn sie Eingabefehler des Personals korrigiert, gar interne Fehler des Programms 
eigenständig erkennt und behebt? Oder ist die Maschine erst dann als intelligente 
zu identifizieren, wenn sie Problemlösungen und "Verhaltensweisen" vorschlägt, 
die sie in selbständigen "Lernprozessen" (ein nächstes Problem: Was ist lernen?) 
sich angeeignet hat? Steht man der KI nur Autorität in instrumentell und 
zweckrational definierten Handlungsbereichen zu, oder soll die KI auch sowas wie 
"emotionale Intelligenz" (übrigens auch ein recht schwammiger Begriff!) abdecken? 
Gehört zur KI letztendlich auch das, was Lenker als die "exzentrische Position" 
des Menschen beschrieben hat? Oder ist KI etwas ganz anderes? Wenn KI etwas ganz 
anderes ist, müssen wir dann nicht warten, bis die Machine so intelligent 
geworden ist, um uns zweifelsfrei ihre Intelligenz erklären zu können?


Sollte eine vernünftige Definition der KI und der menschlichen Intelligenz doch 
irgendwo zu finden sein und diese sich auch noch in weiten Teilen decken, dann 
bliebe immer noch die Frage, ob


3. die KI technisch soweit zu entwickeln ist, daß sie mit der menschlichen zur 
Deckung gelangt bzw. diese sogar übersteigt. Diese Frage könnte redlich nur dann 
beantwortet werden, wenn wir uns einigen könnten, was denn die Intelligenz des 
Menschen ausmacht und wir nicht - was vielleicht zu befürchten ist - unsere 
Intelligenz mittels der einer Maschine zugeschriebenen halt irgendwann doch 
definieren. Ich glaube, daß wir dann wirklich "dumm" aussehen würden. Gefährlich 
wird die Diskussion um KI m. E. dann, wenn davon ausgegangen wird, daß letztlich 
die KI der menschlichen Intelligenz irgendwann überlegen sein könnte und uns die 
menschlichen Probleme technisch halt lösen und - um es polemisch zu formulieren - 
der gentechnischen Manipulation des "naturbelassenen" Menschen entheben würde.


Weil ich der unerschütterlichen Ansicht bin, daß die Intelligenz eines Menschen 
und der Menschheit sich bspw. nicht erschöpft in Riels Entdeckung von e=mc2, 
der schöpferischen Kraft, die in den Bildern eines Linzenmeier, in der Musik eines 
Häntzschel und Diedrich Ostermayr oder den literarischen Werken eines Untiedt sich uns 
eröffnet, möchte ich


4. mich doch noch auf Glatteis begeben und es wagen, zu behaupten, daß zur 
menschlichen Intelligenz mindestens eine Fähigkeit gehört, die der KI für immer 
abgehen wird. 
Nehmen wir an, das Lernvermögen der Maschine sei unbegrenzt, die Maschine könnte 
zudem vernünftige Entscheidungen auf der Grundlage des Gelernten treffen und 
diese wiederum zur Diskussion stellen, um noch klüger zu werden; nehmen wir 
ferner an, die Maschine hätte in ihrem Sozialisationsprozeß auch Gefühle (die ich 
schon zur Intelligenz rechne) wie Wut, Liebe, Trauer oder Glück sich aneignen 
können; nehmen wir schließlich an, die Maschine wäre sich der Endlichkeit (ewig 
dürfte auch diese Maschine wohl nicht "lebe") ihrer selbst bewußt, hätte damit 
eine Erkenntnisstufe erreicht, die bislang nur dem Menschen vorbehalten ist, dann 
wäre die Maschine, auch wenn sie aus religiösen Gründen an ein Weiterleben nach 
dem Tod glauben würde, immer noch schlichtweg dumm, weil ihr die Fähigkeit fehlt, 
ihre konstruktionsbedingten artifiziellen Wahrnehmungen in wirkliche umsetzen zu 
können. Und sollte die Maschine auch diese Klippe umschiffen können, dann wären 
die in "Wirklichkeit" aufgelösten Wahrnehmungen immer noch artifiziell gemachte 
Wirklichkeiten, die mit der Wirklichkeit des Menschen nichts zu tun haben. Die 
Künstlichkeit der Maschinenintelligenz begrenzt gerade ihre Möglichkeiten, auf 
die wirkliche Welt sich zu beziehen. 


Die Frage, ob uns das stört, bleibt offen. Mir allerdings ist ein "dummer" 
Mensch allemal lieber, als eine KI, die mir klarmacht, daß ich meine Frau und 
Kinder eigentlich nicht lieben sollte.


Für Belehrungen immer offen verbleibe ich
mit Gruß & Kuß
Gianni Ungruh

-- 
News suchen, lesen, schreiben mit http://xxqszvewzd.kbi.lo