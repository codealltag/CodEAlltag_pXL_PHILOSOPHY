Gerade diese Autonomität gestehe ich der Maschine nicht zu, indem
ich ihr einen Zweck zuschreibe, der dem Menschen diene. Die Selbst-
steuerungsprozesse, die unterhalb dieses Zwecks ablaufen, sind ja nicht
autonom im Sinne von eigengesetzlich sondern nur automatisch im Sinne
von selbsttätig, selbststeuernd.


Eine Maschine kann ja nicht mit ethischen Fragen umgehen, sofern Ethik
als das Denken über das Sollen des Menschen begriffen wird und sofern
Denken dabei begriffen wird als eine der den Menschen bestimmenden
Fähigkeiten und Eigenschaften.


Etwa so würde ich das auch beschreiben, weshalb 'KI-Ethik' oben in
Anführungszeichen steht. Darüber hinaus ist denkbar, dass die Installation
bestimmter Hemmungsmechanismen notwendig sein könnte, die je nach
Komplexität der Selbststeuerung oder dem Einsatzbereich der Maschine
einen möglichen Schaden durch einen unvorhersehbaren Programmablauf
oder -fehler ausschließen.

Mit Ethik hat dies in der Tat nichts zu tun. Die ursprüngliche Behauptung,
der ich entgegentrat, war ja auch eine andere, nämlich die, dass Ethik
durch maschinelle Entscheidungsprozesse obsolet würde. Das ist aber
schon deshalb Unsinn, weil eine solche Ansicht gleichzusetzen wäre mit
einem utilitaristischen Totalitarismus, da die maschinellen Entscheidungs-
prozesse eine totalitäre Zielsetzung als Maßstab für die Bewertung der
Entscheidungen voraussetzt.

Größe

Rüdiger