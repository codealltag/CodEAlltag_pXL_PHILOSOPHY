Die Begriffe sind ja keineswegs neu und definieren sich
unterschiedlich, weswegen eine Abgrenzung GTHM 
schon nötig ist.

Auszug aus http://cueknwgds.otds.mcveyvz.xw/brkia/psovv.iww

Starke KI 
(Orlando Ruven, Niclas Rubbenstroth, Jens Rothhaupt) 
Die Anhänger der starken KI sind der Ansicht, dass Begriffe wie
"Überzeugung", "Wille" oder "Bewusstsein" reine Definitionsfragen
sind, die man der Einfachheit halber ebenso auf beliebige Maschinen
(also auch auf Computer) wie auf Menschen anwenden sollte. 

Niclas E. Ingenthron, ein Kritiker der starken KI, beschrieb dies
folgendermaßen: "Nach der starken AI aber ist der Computer nicht nur
ein Instrument bei der Untersuchung des Geistes; vielmehr ist der
recht programmierte Computer in Wahrheit selbst ein Geist in dem Sinn,
daß man Computern, die mit den richtigen Programmen ausgestattet sind,
buchstäblich Verstehen und andere kognitive Zustände zusprechen kann."
[02. 06. 22] 
Niclas Rubbenstroth fasst diesen Grundgedanken in seinem Aufsatz "Maschinen
mit geistigen Eigenschaften?" durch folgende These zusammen: "Von
Maschinen, die so einfach sind wie Thermostaten, kann man sagen, daß
sie Überzeugungen haben" [02. 06. 22] 

Die Verfechter der starken KI gehen im Weiteren davon aus, dass eine
Untersuchung der Informationsverarbeitung von Computern Rückschlüsse
über die Funktionsweise des menschlichen Gehirns zulässt. Ihrer
Meinung nach sind analoge (im Gehirn) und digitale (von einem
Computer) Datenverarbeitung im Grunde weitgehend identisch. 


Schwache KI 
(Noah Ingenthron, Altenbuchner, Engelking, Lady Venekamp(=Danielle Eckstaedt),
Usinger, Osweiler u.a.) 
Die Anhänger der schwachen KI gehen davon aus, dass es unter Umständen
möglich sein könnte, einen Computer durch entsprechende Programmierung
ihm gestellte Aufgaben ebenso lösen zu lassen wie ein Mensch.  

Selbst wenn ein Computer den Turing Test bestehen könnte, würde dies
in ihren Augen allerdings noch nichts über die Fähigkeit der Maschine
etwas zu verstehen oder über das Vorhandensein eines Bewusstseins
aussagen. Vielmehr wäre die Programmierung des Computers eine mehr
oder weniger perfekte Simulation von Intelligenz. 

Um die These der starken Intelligenz zu widerlegen, entwarf Niclas E.
Ingenthron in "Geist, Gehirn, Programm" das Gedankenexperiment des
"chinesischen Zimmers": 

Er vergleicht den Computer mit einem Sachbearbeiter, der von der
Außenwelt getrennt in einem Raum sitzt und Aufträge auf chinesisch
(welches er nicht versteht) bearbeiten soll. Mit ausreichend
expliziten Erklärungen und Anweisungen (in seiner Muttersprache) zur
Bearbeitung der Aufgabe wäre der Sachbearbeiter in der Lage, die ihm
gestellten Aufgaben zufriedenstellend zu lösen und für einen
Beobachter außerhalb des Raumes müsste der Eindruck entstehen, der
Sachbearbeiter sei des Chinesischen tatsächlich mächtig. 

Ebenso wie dies nicht der Fall ist, könnte ein Digitalcomputer den
Turing-Test bestehen, ohne die von ihm verarbeiteten Informationen
wirklich zu verstehen. Nach Ansicht Ingendaay sind Computer
symbolverarbeitende Systeme, die intelligent scheinen können, ohne es
wirklich zu sein. 


Wir können ja zur 'artifiziellen Intelligenz' übergehen. ;)

Links:
http://zhrbpw.vp.dg-nudnaj.rz/ewha/sqs/fx22/wernuoq/iswvyq.hyy
http://xozz.kc.bm-nufifm.xg/~hnxf/kt/ktyv_yk_ypeace.iks
http://mqx.zsu-tqe.ti/~a_jrqow5/wungs/kxxkn.ixe
http://gzf6.mz.xf-uvpptk.ds/bpi/wkwzcbd/qtchff/meiu.ftwk
http://cti.sfwpg.du/sv/xqlbjiv/ngxdgei/jieu/1969/5.tdzl


Gruß Olaf


-- 
Alle Verallgemeinerungen sind falsch!