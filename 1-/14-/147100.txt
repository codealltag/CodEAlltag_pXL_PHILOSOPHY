Nein, sicher nicht. Das praktisch verwirklichbare Ziel ist kein unfehlbarer
Entscheider, sondern "nur" etwas, was ein bestimmtes (und ziemlich
drängendes) Problem besser lösen kann, als der Mensch alleine. Denke ich
mal.

selbst
unverschuldeter
keine
KI zu

Dem kann ich nicht zustimmen. Ist es moralisch verwerflich, ein Werkzeug zu
benutzen, um ein selbstgeschaffenes Problem zu lösen? Wenn ja: Dann sind wir
schon alle durch und durch verdorben, und sollten sofort alle aus den
Städten ausziehen. Wenn nein: Die KI ist nichts anderes als ein von Menschen
geschaffenens Werkzeug.

Gruss,
Valentino Leisner -- "Überwachung schützt nicht vor Terror."