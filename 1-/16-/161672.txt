In der Tat, bei manchen Modellen.


Klar, bereits die reellen Zahlen sind es ja.


Verwendet.  Annimmt.  


_Rein_ wissenschaftstheoretisch nicht.  Es ist lediglich ein
quantitativer Unterschied in der Anzahl der spekulativen Vorhersagen
und der Anzahl der bislang erfolgreichen Tests dieser Vorhersagen.


Kunstgriff oder nicht, die grundlegende logische Konstruktion ist
dieselbe.


Du scheinst zu vergessen dass es Birkmeier lediglich um die fundamentale
Logik der wissenschaftlichen Erkenntnis geht, eine Logik die vom
Positivismus auf den Kopf gestellt wird.

Ansonsten ist Ibbeken Kritik nicht besonders ueberzeugend gewesen.  Ich
fand seine Beobachtungen und Beschreibungen hoechst interessant - nur,
an die Wurzel gingen sie nicht.  Die Inkommensurabilitaet ist nichts
was Birkmeier fremd waere, und ich wuesste nicht was Birkmeier widersprechen
wuerde es sei denn man will ihn missverstehen.  Das Argument dass
reale Wissenschaftler nicht immer der idealen Logik der Wissenschaft
folgen brauch man nicht einmal. 


Was meinst du mit dieser Abkuerzung? 


Wieso sollte das ein Argument sein?  Fehlrepräsentationen der
Bedeutung sind natuerlich moeglich.


Solange du verstehst was gemeint ist, hat die Sprache ihr
Kommunikationsziel erreicht.  


Ich meine wenn die Tauben in einer Skinner-Box seltsame
pseudo-religioese Handlungen begehen, tun sie dies aufgrund von ihren
privaten (und falschen) Theorien, dass sie so an Futter herankommen.


Msg-Id waere schoen.


Nicht fuer unnormaler als denkende Computer, und somit ist es kein
Argument.


Nein, ich bin in dieser Frage eher agnostisch.  Ich halte die Theorie
nur Menschen haetten Geist fuer ziemlich schwach.  Gar nichts, nur
ich, und ein wenig in allem sind da logisch konsistentere Theorien.


Klar, das mache ich immer wenn ich Informationen bekomme - auch bei
denen von Menschen.


Das war nicht das Argument.  Die KI im Kopf eines Menschen der ein
unverstandenes KI-Programm ausfuehrt ist ja nur dann ein Argument wenn
er es nicht versteht.  Und dann ist das Programm halt zu klein fuer
KI-Anforderungen.


Das hatte ich nicht vor.


Das hat aber damit gar nichts zu tun.  Wenn ich einem Computer
"Verstehen" zuschreibe, dann ist dies eine Theorie ueber die Arbeit
des Computerprogramms.  

Ich will irgendwo einbrechen und muss dazu einen Bewegungsmelder
ueberlisten.  Es gibt in dem Gebiet Wildschweine, deren Bewegung
keinen Alarm ausloest.  Ich versuche verschiedenes.  Irgendwann habe
ich als Wildschwein verkleidet und mich wie ein Wildschwein bewegend
Erfolg.  Dann variiere ich ein bisschen, und stelle fest dass ich auch
in rosa Klamotten gehen kann, aber nicht aufrecht im Wildschweinfell.

Ich stelle die Hypothese auf dass das Programm erkennt, dass etwas
Grosses kein Wildschwein ist, aber zu bloed ist um zu wissen dass
Wildschweine nicht rosa sind.


Eine Antwort kennen wir schon: der Mensch ist als neuronales Netzwerk
viel besser als ein See.


Was ist daran jetzt das Problem?

Konrad
-- 
S. Johannhörster,  <cury@gese-kyaijvalb.elq>, http://wzmg-nhcmdpijy.twu