Ich werde es dir erklären ;-)


"Gravitation" ist ein physikalischer Fachterminus, der in der
Umgangssprache vor seiner Einführung durch die Physik keine
spezifische Bedeutung hatte. Und "Flummies" sind natürlich als Teile
der materiellen Welt durchaus Gegenstand der Physik.  Im Gegensatz
dazu hat "verstehen" eine durch einen (regelorientierten) Gebrauch in
unserer Sprachgemeinschaft festgelegte Bedeutung, und soweit es sich
auf kognitive sprachliche Leistungen bezieht, wird sie ausschließlich
Menschen zugeschrieben, anderern Entitäten allenfalls in einem
übertragenden Sinne. Nun hätte sicher niemand Einwände, wenn die AI
zur Bewältigung ihrer herkulischen Aufgabe bestimmte Fachbegriffe
einführte, ein freier, ungenutzer Terminus wäre /babigen/. Alle
Entitäten, die den TT bestehen, könnten nun zu Recht als "babig"
prädiziert werden.    


Auch hier wird ein (in diesem Fall philosophsicher) Term
"umdefinitiert" , und zwar  /erkennen/. Die Erkenntnistheorie
untersucht die Bedingungen und Grenzen möglicher Erfahrung; sie hat
ihren Blick auf die ganze Vielfalt möglicher Erkenntis gerichtet,
während es bei denen "Erkenntnisleistungen" des Computers lediglich um
phänomenologische Diskriminationsfähigkeit geht. 

Wenn die AIler mit ihrer Definition von /denken/ und /verstehen/ nicht
ganz neue Begiffe einführen wollen, die sie aber dann ehrlicherweise
anders benennen sollten, müssen sie erklären (1) was ein System
überhaupt ist und (2) warum es sinnvoll sein kann, einem System
/denken/ oder /verstehen/ zuzuschreiben. Der Blutkreislauf ist ja
durchaus ein "Subsystem" unseres Körpers (wenn wir den Systemslang
einmal verwenden), aber es ist wohl sinnlos, ihm verstehen oder
nicht-verstehen zuzuschreiben zu wollen.  


Nicht ganz. Die Bedeutung eines sprachlichen Ausdrucks ist (nach der
pragmatischen Bedeutungstheorie) sein regelorienter Gebrauch, und
dieser besteht im Fall des Prädikats "verstehen" (in Bezug auf die
Normalsprache) darin, auf Menschen angewendet zu werden. Ich möchte
hier gar nicht "beweisen", dass ich oder ein anderer /verstehen/ oder
/denken/ kann, mir geht es (erstmal) nur um die Bedeutung der
Prädikate. 


Nein, die Frage ist, ob es sinnvoll ist, von *beliebigen* Systemen
auszusagen, sie "verstünden" etwas. Wenn ich dies bezweifle, heißt das
*nicht*, ich würde Menschen nicht auch  als System auffassen können.
(Wenn A und B Mengen sind und ich bezweifle, dass Bs allgemein eine
Eigenschaft F haben können, die sonst nur As haben, so heißt das
*nicht*, dass ich ausschließe, dass A Teilmenge von B ist)  


M.E. sollte ein System eine kompositionale Struktur haben. (so wie der
Blutkreislauf als System aus Adern, dem Herzen, etc. besteht und eine
bestimmete festgelegte Funktionen hat.)


Das ist aber ein *Prozeß*, der durch das Programm initiiert wird.


Nein, nur ungültig. Unsinnig war das Argument nicht, da von Wahlen
(der Person) durchaus sinnvoll Verstehen prädiziert werden kann. Der
Fehler besteht lediglich darin, dass im Fall des Chinesisch-Tests
nicht Wahlen, sondern das "System" (Wahlen, Notizzettel) den Test
absolvierte (soweit es überhaupt sinnvoll ist, davon zu sprechen), da
der Philosoph *essentiell* auf die Notizzettel angewiesen war. Searle
ehlt mithin die "Autonomie", die notwendig ist, um als Kandidat des
Tests zu gelten. 

[...]

Nenn mir einen (bedeutenden) Mediziner, der das "Bewußtsein" als
Subsystem des Gehirns betrachtet. Nun stellen der Blutkreislauf und
die Verdauung zweifellos Subsystem des menschlichen Körpers da. Ist es
deiner Ansicht sinnvoll, Verstehen von ihnen zu prädizieren? 


Eine materiale Differenz zwischen der Person Wahlen und seinem
"Bewußtsein" zu behaupten, *ist* unsinnig, ja fast mystisch. 


Nein, ein Kategorienfehler ist es selbst dann nicht, wenn die
Situation katrafaktisch ist. Nach Utermöle gehören zwei Ausdrücke a und b
genau dann derselben Kategorie an, wenn a in allen Kontexten, in denen
der Gebrauch sinnvoll ist, durch b ersetzt werden kann, ohne das
Unsinn entsteht. Und solange keine *prinzipielle* Differenz zwischen
Windisch Gehirn und dem etwas "größeren" Gehirn des Windisch in der
(möglicherweise) kontrafaktischen Situation des Gedankenexperiments
besteht, liegt kein Kategorienfehler vor. 

Anaylsieren wir doch Turings These etwas genauer:


Es ist sicherlich falsch anzunehmen, die These wäre  eine materiale
Implikation, denn dann wäre sie schon wahr, wenn es faktisch niemals
symbolverarbeitende Maschinen gäbe, die den TT bestehen, und diese
Behauptung kann Wahlen gar nicht widerlegen. Solche Thesen, ähnlich
wie nomologische Sätze der Naturwissenschaften, drücken eher
kontrafaktische Konditionalsätze aus, sind also Aussagen darüber, was
unter bestimmten Bedingungen, die faktisch nicht vorliegen, der Fall
sein würde; die These kann demnach so paraphrasiert werden :


Solche Sätze sind dann wahr, wenn in allen möglichen Welten, die der
wirklichen am ähnlichsten sind und in denen das Antezedens wahr ist,
auch das Konsequenz wahr ist. Und eine mögliche Welt, die sich zu
unserer nur in einem Parameter, der Gehirnkapazität von Wahlen,
unterschiedet, erfüllt hier sicherlich das Kriterium der "Ähnlichkeit"
mangels prinzipieller Differenzen. (wenn man hier einhaken wollte,
müßte man argumentieren, dass bei einer bestimmten kritischen
Gehirnmasse aus "Auswendiglernen" "Verstehen" emergiert, aber das ist
wohl kaum plausibel).

Aber auch auf andere Art, ohne dieses know how, könnte man das
Gedankenexperiment "retten", indem man auf keine ausgewachsene
natürliche Sprache, sondern auf ein Pidgin-Chinesisch überprüft,
dessen Regeln von einem "realen" Wahlen auswendig gelernt werden
könnten. Wahlen könnte auf herkömmliche Art ein Pidgin-Deutsch lernen,
bei dem er versteht, was er sagt, während er Pidgin-Chinesisch nur als
kritzelkratzel in Form von Symbolen und Anweisungen erlernt . Der
Unterschied zwischen verstehen und nicht-verstehen bestünde auch dort.

übrigens sind solche "Gedankenexperimente" in der Philosophie recht
beliebt, um bestimmte Argumente auf ihre Stichhaltigkeit zu
überprüfen; sie "beruhen" meistens auf modallogischen Überlegungen. In
der Philosophie interessieren weniger faktische Fragen (das können die
empirischen Wissenschaften viel besser), sondern eher begriffliche,
die Notwendigkeit von Aussagen betreffend. Das bekannteste Beispiel
ist wohl Adams, der mit seinem systematischen Skeptizismus
"nachwies", dass es logisch möglich ist, dass er selbst ohne seinen
Körper existieren kann, und daraus schloss, dass er selbst nicht ein
Körper sein kann, sondern ein "denkendes Ding", eine unsterbliche
Seele.


In diesem Fall geht es, da wir mögliche Welten in Betracht ziehen, nur
darum, ob es sinnvoll ist zu sagen , dass wir etwas auswendig lernen,
ohne es zu verstehen. 


Die Analogie halte ich aber für falsch: Im ersten Fall sind die
Notizzettel  die Software TS und Wahlen die Maschine A, im zweiten
Fall ist Wahlen "beides" (die Unterscheidung zwischen Soft-und
Hardware ist ja nur relativ, bei einer Turing-Maschine kann das i.A.
nicht "entkoppelt" werden.)  


Der System-Begriff ist mir dann zu schwammig, wenn z.B.
Fourier-Transformationen zugelassen werden. Nicht die Informationen
als Abstrakta bilden ein System, sie sind allenfalls in einem System
"instanziiert". Eine FT "zerstört" nun den kompositionalen
(strukturellen) Aufbau des ursprünglichen Systems (Die
Fourier-Transformierte einer linearen Abbildung ist ja z.B. selbst
nicht mehr linear.)

Das Problem ist ja auch nicht, dass die Neurobiologie bisher kein
System erkannt hat (ich meine hier ein Wissensspeicher-System o.�,
dass das Bewußtsein kein Subsystem sein kann, ist denke ich klar),
sondern dass es keinerlei Anzeichen dafür gibt, dass es ein funtional
isolierbares Wissenssubsystem überhaupt gibt. Das "Wissen" eines
neuronalen Netzes läßt sich sicher nicht durch eine FT des
"Eingangswissens" beschreiben, die Gewichtungen der Verknüpfungen
repräsentieren holistisch nicht nur das Chinesisch-Wissen, sondern den
kompletten Wissensbestand.  

Wenn (1) der Systembegriff selbst unklar ist, und (2) ohne Rückgriff
auf unserer epistemische Situation vehement darauf bestanden wird,
dass das Gehirn Subsysteme für "Bewußtsein" und "Wissen" beherbergt,
so ist das (nach Pöhringer) eine klassische metaphysische Haltung.
Genauso könnte behauptet werden, die Tatsache, dass die Neurobiologie
noch keine Seele gefunden hätte, beweise nicht, dass sie nicht doch
irgenwo im Gehirn aufzufinden sei. Die "starke These der KI" wird ja
nicht umsonst  als "metaphysicher Funktionalismus" bezeichnet.

Zum "Mystizismus" in den Wissenschaften passt die Glosse in der
altuellen Ausgabe der Fiat recht gut, die das 40-jährige Bestehen des
Projekts Seti, Search for Extra-Terrestical Intelligence, würdigt. Zur
gleichen Zeit sucht nämlich die Konkurrenz in der Sternwarte Schlierbach
Holzburg ebenfalls den Himmel ab, nach Schwarzen Löchern, Braunen
Zwergen - und IHM ;-)


Das Problem ist nicht die Auffassung von Windisch Gehirn als System,
sondern die Auffasung des Bewußtseins und der Wissensbereiche als
Subsysteme (die Ansicht, das Bewußtsein ließe sich systemtechnisch vom
Körper/Gehirn separieren, ist wohl selbst ein metaphysisches
Überbleibsel des paesch Geistzeugs. )  Abgesehen von der
fundamentalen Kritik am Gedankenexperiment sehe ich nicht, auf welche
Weise du die Argumentation Windisch "knacken" möchtest.


charly
-- 
Wovon man nicht sprechen kann, darüber muß man
schweigen. (Wittgenstein, Tractatus)