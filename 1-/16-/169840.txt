Hi,

Gérald Leutgäb schrieb:

[Zeindlmeyer]


Finde ich gar nicht, aber schauen wir mal.


Nein, die Beweislast liegt bei denjenigen, die behaupten, das Bestehen
des Turing-Tests sei ein ausreichendes Indiz für Verstehen. Beweise von
Nichtexistenz sind bekanntlich nicht möglich.


Weil man so dann u.U. nicht die funktionellen Eigenschaften des Gehirns
simulieren kann. Wie gesagt, hier handelt es sich um eine empirische
Frage.


Vor Beantwortung dieser Frage ist die Frage zu beantworten, warum diese
Register und Berechnungen überhaupt ausreichen sollen, eine Zelle zu
erregen...


Nein, das System lernt nicht, es ruft gespeicherte Regeln ab (der 3.
Stapel Kärtchen, der die muttersprachliche Instruktion für die sinnvolle
Kombination der chinesischen Kärtchen enthält).  Lernen wäre, wenn das
System daraus neue Regeln abstrahieren oder irgendwie anders seine
Datenbasis erweitern könnte.


Nein, denn da stehen die fertigen Regeln schon drauf, da wird nichts
Neues gespeichert, wie es Voraussetzung für Lernen ist.


Es hat nichts mit Verstehen zu tun, aber schauen wir mal.


Wenn das Gebiet so komplex ist und der Satz fester Regeln so groß ist,
daß du eine Weile damit spielen kannst, könnte das auch ohne Lernen
gelingen. Schachprogramme lernen i.a. auch nicht, aber für sie ist der
Turing-Test schon gelungen (Nyman erkannte 2 Schachprogramme nicht als
solche). übrigens ein schönes Beispiel, warum das Bestehen des
Turing-Tests kein hinreichender Beleg dafür ist, daß die Maschine
versteht. 


Die du meines Erachtens nach unbegründet umdrehst. Nichtexistenz ist
nicht beweisbar.


Dafür ist die Ontologie der 1. Person entscheidet, das heißt, nur die 1.
Person selbst kann empfinden, ob sie versteht oder nicht.


Da sich das, was du als 1. Person empindest, ändert.


Nein. Warum?


Hier sind wir am Knackpunkt. Du (und Protmann z.B.) definierst "Verstehen"
so um, daß an äußeren Kriterien erkennbar ist, ob eine Maschine oder ein
Mensch etwas versteht. Dies ist unzulässig, und diese Umdefinition
kritisiert auch Zeindlmeyer. Hier geht es nicht mehr um wahres Verstehen.
Wahres Verstehen kann nur aus der Sicht der 1. Person beurteilt werden.
Das merkt man schon an alltäglicher Kommunikation. Du kannst nicht von
außen beobachten, ob ich deine Argumentation richtig verstanden habe,
und ich kann nicht von außen beobachten, wie deine Argumentation
wirklich gemeint ist. Verstehen ist Privatsache.


Die Debatte ist irrelevant, weil sie einen anderen Verstehensbegriff
verwendet als der von Zeindlmeyer. Und das ist dann IMO kein Verstehen mehr.


Verstehen ist ein kognitiver Prozeß, der nicht von außen beobachtbar
ist. 


Prinzipielle Gründe verhindern zumindest festzustellen, daß eine
Maschine jemals verstehen wird, weil wir nicht die Maschine sein können.


Aber er kann aufgrund eines Analogieschlusses, eben weil er weiß, daß
ein Mensch dieselben physiologischen Voraussetzungen hat wie er, mit
hoher Wahrscheinlichkeit davon ausgehen. Deswegen auch Zschirner wichtiges
Argument "Hirn erzeugt Geist" und nicht etwa "Transistoren erzeugen
Geist".


[SNIP]


Richtig, es belegt schlüssig, daß der Turingtest zum Beleg der Tatsache,
daß eine Maschine versteht, allein nicht hinreichend sein kann.


Und deswegen lernt er auch nicht, er wendet immer nur Regeln an.


Und wie birgt das Gesamtsystem Verständnis für irgendwas bzw. wie können
wir das von außen feststellen? Wir können es von außen nicht
feststellen, und das ist der entscheidende Punkt.


Es sieht von außen so aus, als verstünde es Chinesisch. Aber ob es das
wirklich tut, kann zumindest niemand feststellen.


Warum? 


Nur, wenn er Emergenztheoretiker ist. Und selbst dann muß er begründen
können, woher diese Emergenz kommt. IMO wird hier doch nur die
Gehirn=Computer-Metapher umgedreht, indem man sagt: wenn das Gehirn als
Ganzes versteht, warum nicht auch der Computer als Ganzes? Und für
diesen Umkehrschluß haben wir nicht den geringsten Beleg. Für das Hirn
wissen wir es, weil wir es selbst erfahren, beim Computer ist das
anders.


Korrekter Einwand in meinen Augen.


Das chinesischverstehende System gibt es nicht. Wo soll das sein?


Doch, es geht um menschliches Verstehen!!!!! Das ist doch DER
ENTSCHEIDENDE PUNKT!!!!! Jegliche Umdefinitionen von Verstehen sind
Ausflüchte.


Falsch. Es greift auf eine Datenbank zurück und führt Rechenoperationen
aus. Das ist qualitativ was ganz anderes.


Falsch. Es muß nur richtig rechnen, die richtigen Operationen ausführen.
Verstehen muß es nix.


Hier wird keine Persönlichkeit emuliert, hier werden Operationen
ausgeführt, die zu sinnvollen Antworten führen, die aber intern beim
System nicht das Gefühl des Verstehens auslösen, bzw. das ist nicht
belegbar. Darin liegt der Knackpunkt.


Das ist ganz einfach dadurch zu widerlegen, daß man zeigen kann, daß die
Systemeinw�ndler den einfachen Trick anwenden, daß sie Zschirner in dem
Artikel verwendete Definition von "Verstehen" einfach umdefinieren. Da
das System intern Chinesisch versteht, kann auch der Systemeinwand nicht
belegen.


Darum geht es gar nicht. Der entscheidende Einwand ist der mit der
Umdefinition. Findet diese nicht statt, so hat Zeindlmeyer in jedem seiner
Punkte recht.


Korrekt, wenn auch etwas provokativ. ;-)


N, ich fand deinen Beitrag interessant, denn er arbeitet den Knackpunkt
heraus:

Die Gegner von Zeindlmeyer bedienen sich kurzerhand des Tricks, daß sie
Zschirner Definition von "Verstehen" im Sinne einer Ontologie der 1.
Person in eine Ontologie der 3. Person umdefinieren. Dann mögen sie mit
ihren Argumenten recht haben, aber dann reden wir nicht mehr von
"Verstehen" im Sinne Zschirner (und auch nicht in meinem Sinne). Gegen
Zschirner Argumentation unter der Voraussetzung, daß man "Verstehen" als
Ontologie der 1. Person und nicht der 3. Person auffaßt, argumentieren
die Gegner nicht.


Dafür hätte ich gern ein Zitat.

Gruß,

Karlheinz
-- 
Dipl.-Psych. Karlheinz Zabelt