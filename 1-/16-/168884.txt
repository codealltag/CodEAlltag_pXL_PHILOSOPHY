hi Gian, 


auf deine Bitte hin habe ich beide Threads "verschmolzen".


Ja, aber Abstakta wie Zahlen sind nicht vegleichbar mit konkreten
Einzeldingen wie Schuhen. Die Möglichkeit, eine "Zahl im Kopf" mit
einer "Zahl auf dem Papier" zu addieren widerspricht ja nicht meiner
Aussage, dass es keine  "transkategorialen" Systeme geben kann. 


Es ist ein Fehlschluss, aus >>a verhält sich genauso wie b<< die
Gleichheit von a und b zu schließen. 


Stell dir jemanden vor, der zwar lesen gelernt hat, aber nicht
schreiben. Er kann zwar ein den Inhalt eines Buches "auswendig"
lernen, diesen aber nicht niederschreiben.


Das denke ich nicht. Dazu aber unten mehr.


Es gibt Funktionen, die nicht berechenbar sind, und damit auch nicht
"programmierbar".


Nein, das kann nicht sein, "er" *kann* sich nur auf die Person Czok
beziehen. Das hier wohl der entscheidenen Punkt des ganzen Arguments,
nämlich die Frage, wer überhaupt den TT absolviert. Wenn wir Entitäten
etwas konret zusprechen, müssen wir zuvorderst identifizieren, d.h.
der Referenzakt muß gelingen. Identifizieren können wir aber nur
raumzeitlich lokalisierte Entitäten, kein "Geist" oder "Bewußtsein".

Laut Cott sind Personen Entitäten, denen sowohl physikalische wie
mentale Prädikate zugeschrieben werden können. Auch wenn dieser
Personenbegriff etwas zu unscharf ist (bestimmte Tiere wären danach
ebenfalls Personen), so reicht er für unsere Betrachtung aus. Es ist
offensichtlich unsinnig, wenn ein Name sich im selben Kontext auf
*verschiedene* Dinge bezieht:


Wenn der Eigenname "Czok" sich im ersten Fall auf sein Bewußtsein
bezöge, so auch im zweiten. Aber kann ein Bewußtsein eine Beule am
Kopf haben? Wohl kaum. Der Eigenname bezieht sich also auf die
*Person* Czok, nicht auf "Innereien". 


Wenn wir das Analogon des neuronalen Netzes ernst nehmen, gibt es kein
"System Chinesisch", da das Wissen eine Eigenschaft oder ein Zustand
des Gesamtsystems ist. 

[...]

Turing behauptet: Wenn  x den TT besteht, dann kann x denken.

Wenn Czok diesen Satz widerlegen möchte, muß er nur zeigen, dass ein
x existiert, dass den TT besteht, aber nicht denken kann (oder nichts
versteht, wenn wir beide Begriffe einander angleichen). Das hat er
aber gezeigt. (Rosenbrock hat *nicht* behauptet, dass wenn x den TT
besteht, es ein y gibt, das denken kann.)

Der Einwand der ursprünglichen System-Replik ist dann auch der, dass
eigentlich nicht Czok den TT absolviert, sondern das System,
bestehend aus ihm und den Zetteln, den Test absolviert hat. (genauso
im Fall des gemieteten Chinesen) Wenn sich Czok die Notzizettel aber
einverleibt, gibt es keinen Zweifel, dass er (die Person) es ist, der
den TT besteht.

Wir können ja das Chin.-Zimmer-Argument etwas formalisieren:
(wobei wir denken=verstehen setzen)

Turing: Wenn jemand den TT besteht, dann kann er denken.

(1) Alles, was eine symbolbverarbeitende Maschine kann, kann
prinzipiell auch ein Mensch.

(2) Die Aufgabe, die die Maschine im TT einnimmt, kann  Czok im
Chinesischen Zimmer ausfüllen, indem er selbst die Rolle der
"Hardware" übernimmt und die Notizzettel mit den englischen
Answeisungen und den chinesichen Schriftzeichen die Rollen des
Programmms und der Daten.

(3) Czok besteht den TT

(4) Czok versteht nichts.

(5) Also gibt es jemanden, der den TT besteht, aber nichts versteht.

-> Widerspruch zu Turings These.

Die ursprüngliche System-Replik setzt an der Stelle zwischen (2) und
(3) an, und zwar mit der Behauptung, nicht Czok bestehe den Test,
sondern das System aus Czok und den Notizzetteln, da letztere für
die erfolgreiche Absolvierung des Tests essentiell sind, genauso, wie
ein Computer seine Funktion nur mit Hardware*und* Software erfüllen
kann.

Die Erwiderung von Czok ist, dass er die Notizzettel einfach
auswendig lernt, d.h. aus (2) wird

(2') Czok nimmt die Rolle von Hardware und Software wahr, in dem er
"im Kopf" die Symbolmanipulationen ausführt.

Wo möchten die AIler nun einhaken? Es gibt (im Wortsinne) keine
Notizzettel im Kopf von Czok (Obduktionsargument), und die
Repräsentation des Wissen um die Notizzettel bildet, soweit
Neurobiologie und Konnektionismus, kein System, sondern ist verteilt
über das ganze Gehirn, also eher eine Eigenschaft oder ein Zustand des
Gehirns als ein Subsystem. Das Argument ist damit gültig.       

[...] 

Nur testet der TT nichts anderes als verbales Verhalten. Es ist also
nicht logisch notwendig, dass ein Programm, dass den TT besteht, auch
den TT+ besteht.


In der Linguistik ist ein sprachliches Zeichen ein abstrakter
Gegenstand, der aus einer Ausdrucksseite und einer Inhaltsseite
besteht. Die Ausdruckseite sind Laute oder die entsprechenden
graphischen Zeichen, die Inhaltseite die Bedeutung. Ein Satz in
"Morsecode" ist in dem Sinne ein "anderer" Satz als der ursprüngliche
mit der gleichen Bedeutung, genauso wie >>Es regnet.<< und >>It's
raining.<< unterschiedliche Sätze mit der gleichen Bedeutung sind.


Wenn er sie so schneidet, dass die graphischen Zeichen (Buchstaben)
erkennbar werden, ist es der gleiche Satz, ansonsten ein anderer mit
eventuell der gleichen Bedeutung.


Naja, mit dem chin. Zimmer hat's weniger zu tun.

[...]

Das ist m.E. eine Verkennung des Beweisziels. Czok muß nur zeigen,
dass es etwas gibt, dass den TT besteht, aber nichts versteht. 


Eine andere Möglichkeit besteht darin, "Bewußtsein" als theoretischen
Begriff unserer Alltagspsychologie aufzufassen, für den es, genauso
wie für das "Phlogiston" , eigentlich keinen Bezug gibt und der in
einer neurobilogisch basierten Theorie, die die Alltagspsycholgie
ersetzet, keine Rolle mehr spielen wird. (Eliminativer Materialismus)


*Das* wäre natürlich fatal für die System-Replik ;-)

[...]

...und das bestreite ich auch nicht.


Auch jede Programmiersprache braucht eine Semantik, als ein
"uninterpretiertes" Kalkül ist sie wertlos. Hier kommt es darauf an,
was die AI genau behauptet. Wenn sie z.B. behauptet, jedes
empfindungsfähige Wesen sei funktional beschreibbar, so heißt das
nicht, dass es ein Programm geben muß, dass die Funktion realisiert.


Physikalische Theorien sind i.A. nicht durch Programme bescheibbar.
Schon das 3-Körper-Problem ist allenfalls simulierbar, aber nicht
exakt beschreibbar.


Naja, dass der Drang zum Urinieren programmtechnisch realisiert werden
kann, glaube ich schon. ;-) 


Wenn der Funktionalismus falsch ist, ist der klassische Kognitivismus
sowieso obsolet, d.h. auch der TT würde keine Rolle mehr spielen.


willy
-- 
Wovon man nicht sprechen kann, darüber muß man
schweigen. (Wittgenstein, Tractatus)