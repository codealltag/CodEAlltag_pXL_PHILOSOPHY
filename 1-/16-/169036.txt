In article <kk5xtkj6a4enlh91quu76mb3r1k9vbj4nj@1js.sve>,

Nein, den meinte ich nicht. Ich meine verschiedene Modellansätze der
Quantenphysik, die zwar jeweils "vollständig" sind, sich aber
ausschließen. Oder so ähnlich. Ich habe das aus einem Artikel im
pantinchen aus dem letzten Jahr... kann auch sein, daß
ich mich irre. Egal.

[...]

Ich nehme aber nicht die Position des Solipsismus ein :-)
(altbekanntes) Gedankenmodell: Wir und unsere Umwelt sind Software, die
auf dem "Universums-Computer" abläuft. Das ist hoffe ich auch für
Freunde des Chinesischen Zimmer zumindest vorstellbar. Falls es so
wäre, würde es von uns nicht direkt bemerkt werden (in dem Sinne, daß
es nichts daran ändern würde, wie wir die Welt erfahren). In dem Fall
könnte man "Information" doch die Rolle eines Urstoffes zuschreiben,
oder? Da die zugrundeliegende Hardware unserer Erkenntnisfähigkeit
entzogen bleibt, bleibt nur die darauf gespeicherte Information
als "niedrigste und gemeinsame Stufe" des erkennbaren Seins übrig.

[...]

Die Frage ist dann wohl, was "erlernt" bedeutet. Angenommen wir haben
eine Person, die eine Sache nicht kann/kennt. Sie befindet sich in
Zustand A. Nun gibt es Weg X, der sie in Zustand B versetzt, in dem sie
die Sache kann/kennt. X ist "lernen". Macht es einen Unterschied, wie X
beschaffen ist, solange B identisch bleibt? Genauer, gibt es
verschiedene X für dasselbe B? Falls Computer-der-verstehen-kann
endlich wäre (mir endlich vielen Zuständen), sollte es beliebig viele X
(mit beliebig großer Redundanz) für jedes Paar (A,B) geben (also ob das
Programm selbst lernt, oder die entsprechenden Prädikate auf anderem
Wege "einprogrammiert" bekommt, das Resultat ist dasselbe).


(1) Intelligente Menschen (und Programme auch, behaupte ich mal :-)
würden die grobe Pauschalisierung "Alle blauen Dinge sind häßlich"
nicht sagen _und_ dabei ernst nehmen. Davon gehe ich mal aus.
(2) Wie willst du einem Programm beim Turing Test ein blaues Auto
zeigen, ohne daß du ihm explizit sagst, daß es "blau" ist?


Und ein Programm, welches über das entsprechende Kontextwissen verfügt
(es erlernt hat/einprogrammiert bekam) doch auch, oder?


Ich bin mir nicht sicher, ob du mich verstehst. Der "Geist" benötigt
IMHO schon einen Körper ("Hardware"), auf der er "laufen" kann, ich
gehe nur nicht a priori davon aus, daß ein "Geist" nicht auf
unterschiedlicher "Hardware" existieren könnte. Erklär doch mal, was du
mit "embodied Mind" meinst, falls das dem grundlegend widersprechen
sollte.

[...]

Hast du ein Beispiel für eines, welches von einem Menschen der keine
Sinneseindrücke hat (außer des Symbolflusses aus dem TT-Terminals,
schwimmt im sensory deprivation tank oder so) erfolgreich gelt werden
könnte, von einem Programm aber nicht?

[...]

Ich stimme dir zu, aber ich glaube, du hast nicht verstanden, worauf
ich hinaus wollte. IMHO benutzen wir aus _Effizienz-Gründen
die "Außenwelt" in unserem Denken mit. Das führt aber nicht
notwendigerweise dazu, daß wir die Fähigkeit "zu verstehen" verlieren,
wenn wir dies nicht tun können, und bedeutet erst recht nicht, daß wir
kein (wie sehr abstrahiertes auch immer) Modell der Welt im Kopf haben.
 Nimm mal "strategisches Denken" in seiner allgemeinen Form. Du
jonglierst verschiedene mögliche Handlungsweisen im Kopf, und versuchst
diejenige zu finden, die das beste Ergebnis liefert. Ist es notwendig,
daß du einen direkten Sinneseindruck über einen potentiellen
Handlungsweg hast oder gehabt hast, um ihn "zu verstehen"? Falls nicht,
was wenn nicht dein Weltmodell erlaubt dir, verschiedene potentielle
Handlungsweisen zu konstruieren?


Ja, aber nur weil es schwierig ist, bedeutet das dann daß jemand
der "blind" Schach spielt nicht versteht was er tut? Ein weiteres
Beispiel: Mathematik. Manche mathematischen Modelle entziehen sich
jeder Art von Visualisierung, und können nur "abstrakt im Kopf"
verstanden werden - ganz gewiss, ohne die Außenwelt mit einzubeziehen.

[...]

Ich habe ja auch nicht von "auf andere Art nachweisbaren" Beispielen
gesprochen. Sondern davon, ob eine Person eien "Willen" hat oder nicht.
Da wir dies nicht auf andere Art "zufriedenstellender" nachweisen
können, nehmen wir hier den Anschein als Grundlage für die
Identifikation. Die überwiegende Mehrheit der Menschen wenigstens.

[...]

Dann sehe ich aber nicht ein, warum das Chinesische Zimmer zeigen soll,
daß digitale Computer aus Prinzip nicht denken können,
andere "Maschinen" aber schon. Farrenkothen beschreibt ja ausdrücklich nicht,
wie das Zimmer intern funktioniert (also die Algorithmen etc.); er kann
daher auch schlecht behaupten, daß diese ihm unbekannte Funktionsweise
nicht von einem digitalen Computer durchgeführt werden könnte.


Nunja, "euphorisch" würde ich das nicht nennen ;-) Ich beziehe mich auf
die Ansätze, die z.B. in "Fluid Concepts & Creative Analogies :
Computer Models of the Fundamental Mechanisms of Thought / by Italo
L. Vorndamm" gezeigt werden. Ich glaube, ich habe das in diesem
Thread schon desöfteren erwähnt :-) Ich halte es für zumindest
wagemutig über den Stand der AI zu reden, ohne dieses oder
vergleichbare Bücher/Texte zumindest überflogen (die Kernideen
verstanden) zu haben.

Gruss,
Dirk Uler


Sent via Ologa http://gad.sxkh.frw/
Before you buy.