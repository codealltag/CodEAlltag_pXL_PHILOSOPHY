In article <wmilryu2b20qe53e9xta9fg8mhzy9t81ru@4np.lsp>,


Warum? Das verstehe :-) ich nicht so ganz. Das ist als ob du sagen
würdest: "Gravitation wirkt auf Menschen. Da sie auch auf kleine rosa
Flummies wirkt, das muß die Flummieindustrie erst mal zeigen".
Stattdessen begnügt man sich ja in der Regel mit "Gravitation wirkt auf
Materie", und impliziert stillschweigend, daß sie auch auf kleine rosa
Flummies wirken würde, da die vermutlich so wie alles andere aus
Materie bestehen.
 Aber kann man nicht analog der Ansicht sein, daß "verstehen" sich auf
Entitäten bezieht, die zu kognitiven Leistungen einer bestimmten Art
fähig sind - und also davon ausgehen, daß auch bei Computern (die ja
prinzipiell zu kognitiven Leistungen fähig sind - wenn du mir das nicht
glaubst, dann nimm statt "kog. leist." eben das, was Computer
an "erkennen+reagieren" eben können) die _M�glichkeit_ nicht a priori
auszuschließen ist, daß sie "verstehen" können?

Alternativ: Wie zeigen die Philosophen, daß Menschen (Menschen, nicht
nur "ich selbst") verstehen können? Ich hoffe sie
definieren "verstehen" nicht einfach mit "das, was Menschen können und
andere nicht". Das wäre dann wohl zu billig.


Und grüne Ideen schlafen immer noch zornig... Bist du also der Ansicht,
man kann "Mensch" nicht als System auffassen?


[...]

Ich rede von der Ausführung (in der Zeit) des Programmes TS auf
entweder der Hardware A oder der virtuellen Hardware AS. OK?


[...]

OK. Das kann ich akzeptieren. Das impliziert aber, daß es unsinnig wäre
eine Einzelkomponente auf "verstehen" zu testen, und bei "nicht
bestehen" ihr die Fähigkeit zu "verstehen" abzuerkennen, oder?
Will sagen, vor Folman Einwand auf die System-Replik war das
Chinesiche Zimmer Argument also (deinen Worten nach) unsinnig.


[...]

Hab ich doch gemacht! Deshalb habe ich versucht, dir "deinen"
Kategorienfehler ;-) anhand der Analogie mit den virtuellen Maschinen
zu verdeutlichen.


Warum? Erklär das mal einem Mediziner, das Frohnhofen nicht als
verschiedene (konnektierte) Subsysteme aufgefasst werden kann...


Falsch. Dies ist keineswegs unsinnig, sondern die einzig mögliche
Folgerung aus Folman "unsinnigem" Anspruch, er würde das komplette
Chinesiche Zimmer (mit allen Regeln, Zetteln und Zustandinformationen)
auf "abstrakte, objektive" Art und Weise auswendiglernen.

Ich habe nichts dagegen, daß Frohnhofen im Gedankenexperiment das Zimmer im
Kopf simulieren will. Aber: Frohnhofen die reale Person mit seinem real
existierenden Gehirn _k�nnte_ das nicht. Die für das funktionieren des
chinesichen Zimmers notwendigen Informationen sind nach derzeitigem
Stand der AI viel zu "viel", viel zu Aufwendig, um von Frohnhofen in
einer "objektiven, nicht verstehenden Art und Weise" erinnert zu
werden. Um einige Größenordnungen zu viel. Das bedeutet aber, daß falls
der gedachte Frohnhofen das Zimmer auswendig lernt, man keinen
Analogieschluss mehr zwischen seinem Gehirn und "menschlichen Gehirnen"
ziehen kann (!) Tut Frohnhofen das doch, so begeht _er_ einen
Kategorienfehler.

 Um deine Argumentation von oben zu spiegeln: Wenn Frohnhofen behauptet, er
könne das Chinesische Zimmer auswendiglernen, dann muß er erst einmal
zeigen, daß dies einem menschlichen Gehirn (mit Fähigkeit zu Verstehen)
möglich sei. In Anbetracht der Tatsache, daß ein menschliches Gehirn
noch nicht einmal das "Innenleben" eines handelsüblichen
PCs "auswendiglernen" und "in Gedanken abarbeiten" kann, kann dieser
Einwand von Frohnhofen glaube ich getrost als nonsens angesehen werden (wie
gesagt, falls er das mit einem menschlichen Gehirn tun will).


OK. Oder eben das System aus transhumanem Gehirn (mit auswendig
gelerntem Zimmer) und Folman Körper (Gehirne ohne Körper funktionieren
ja nicht).


Mit der Analogie der Software TS und der virtuellen Maschine AS, die
die Aufgabe der Hardware A übernimmt (auf der TS früher lief) wollte
ich zeigen, daß das an der Sache im Prinzip nichts ändert.


Nur weil die Neurobiologie bisher kein System erkannt hat, bedeutet das
nicht, daß keines existiert. Information kann auf viele Arten
gespeichert werden. Beispiel Fourier-Transformation (wie schon von
Fredi angeführt): Du FTst ein Musikstück und speicherst es als
Frequenzspektrum ab. Jetzt ist das "Wissen" um die Amplitude zu einem
bestimmten Zeitpunkt _auf die gesammte Datenstruktur_ verteilt. Das
heißt aber noch lange nicht, daß kein System dahinter steckt (und erst
recht nicht, daß das, was dieses Wissen rekonstruiert kein Turing-
Maschine-Äquivalent sein kann).

Mir scheint, das Hauptkommunikationsproblem zwischen uns ist, daß du
Folman Gehirn nicht als "System" annerkennst, sondern ihm eine gewisse
metaphysische Sonderstellung einräumst...?

Daniel Lengg


Sent via Azuseb http://joa.nwer.jib/
Before you buy.