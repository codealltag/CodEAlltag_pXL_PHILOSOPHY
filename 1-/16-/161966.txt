Hallo,

dann

Wenn eventuell in natürlichen Gehirnen ablaufende Fehlerkorrektursysteme so 
funktionieren würden, müßten sie fehlerlos die ungestörte Gehirnaktivität 
simulieren - denn Messungen im gestörten Resthirn werden keine "Soll-Werte" 
liefern -, und dann könnte man sich den Rest des Gehirnes sparen.
Viel plausibler wäre es, daß ein Fehlerkorrektursystem bestimmte feste Tests 
durchführt und dann entsprechende Signale zur Fehlerbehebung an die fraglichen 
Hirnareale schickt - und das wäre wieder simulierbar, wenn das 
Fehlerkorrektursystem nicht selbst bei auf Störungen mit Funktionsausfall 
reagieren würde (und wenn es das täte, wäre es nutzlos).

Irgendein Mensch x, dessen Verhalten man vielleicht vorhersagen will.
Die langfristige exakte Verhaltensvorhersage wird in einigen Bereichen wohl 
scheitern, weil bestimmte Aspekte des menschlichen Verhaltens chaotisch sein 
werden. Die Simulation eines menschlichen Gehirns zum Zweck der Steuerung 
eines Androiden mit menschenähnlicher Intelligenz dagegen würde wegen der 
Fehlertoleranz menschlicher Gehirne funktionieren, wenn genügend 
Rechenkapazität zur Verfügung stünde.

Wenn die KI auf der Simulation eines menschlichen Gehirnes beruht, wird sie 
die gleiche Art von Einfällen haben wie ein Mensch.
Im übrigen erscheint mir der Begriff "Rekombination aus Bekanntem" als sehr 
schwammig und mehr oder minder auf alles anwendbar, was Menschen tun.


Oh, ich bin überzeugt, daß auch ein gut programmierter PC heutzutage etwa 
99.99 Prozent aller Schachspieler ohne weiteres schlägt ;).


Ich finde es aber sinnvoll, darauf hinzuarbeiten, daß man Maschinen bekommen 
möge, die auf allen Gebieten menschenähnliche Intelligenz oder mehr besitzen.
Ein Computerprogramm, mit dem ich mich während einer Partie Schach nebenbei 
noch über den neuesten Skandal in der Roboterregierung und die Zukunft der 
künstlichen Intelligenz unterhalten kann, wäre einfach viel interessanter als 
eines, dessen einzige Fähigkeit darin besteht, mich im Schach zu schlagen.


Ich bin auch der Meinung, daß eine hochentwickelte künstliche Intelligenz 
nicht die gleiche Intelligenzstruktur haben müsste wie ein Mensch; tatsächlich 
könnte es sich herausstellen, daß man Intelligenz auf viel effizientere Weise 
erzeugen kann, als es in menschlichen Gehirnen geschieht.
Aber wenn man ein Gehirn simulieren würde, bekäme man ein 
Datenverarbeitungssystem mit menschenähnlichem Verhalten.


Ein hochentwickeltes KI-System wird gelegentlich Fehler machen und manchesmal 
werden hochentwickelte KIs auch verrückt werden.
Ich sehe darin nichts schlimmes, weil das Menschen auch passiert.


Das Gehirn wurde auch durch die natürliche Evolution entwickelt, die viel 
dümmer ist als die Gemeinschaft menschlicher Wissenschaftler, die heute an der 
Entwicklung künstlicher intelligenter Systeme arbeitet.


Wenn man bei künstlicher Intelligenz an Roboter denkt, hat man sowieso in der 
Interaktion mit der Umwelt dauern ein analog-chaotisches Element im System.

Größe,
Onno.