Nicht zu beliebigen Programmänderungen.
Menschen beispielsweise sind mobile datenverarbeitende Maschinen (Roboter), und 
einige ihrer vorprogrammierten Ziele behalten sie ihr Leben lang.
Wenn ich also beispielsweise dafür sorgen würde, daß der Teil der 
Programmierung eines Roboters, der diesen dazu bringt, das Ziel zu haben, daß 
möglichst viele Menschen möglichst glücklich sein sollen, nicht durch 
Lernprozesse verändert werden könnte, dann gäbe mir das eine gewisse 
Sicherheit.


Wie gesagt sehe ich nicht, daß der Lernprozess gleich *beliebige* Ziele des 
Roboters verändern können müsste.

meine
In einem technischen Sinne schon. Ich finde nicht, daß es zur Definition des 
Begriffes "Roboter" gehören sollte, daß die zentrale Datenverarbeitungsanlage 
der jeweiligen autonomen Maschine nichtbiologischer Art sein sollte.

Größe,
Valerio.