Hallo Volkert,

Programm

Woche
auch
nicht

Dieser Vergleich passt nicht ganz. Unser alter Vergleich, den wir bei Maderholz
verwendet haben, passt besser. Er passt besser doch:

"Reuschenbach kann diesen Programmsatz nicht widerspruchsfrei aussagen"

Ich gehe mal davon aus, Reuschenbach sei ebenfalls ein MBC (Modell - Penrose;
unser vorheriger KI (Emmerich Imperator)). Jetzt spricht aber unser echtes ARTUR:

WERA:  Mein Reuschenbach - Modell sagt voraus, dass sie das sagen würden. Es zeigt
auch, wie sie auf  "Reuschenbach kann diesen Programmsatz nicht widerspruchsfrei
aussagen" reagieren werden. Effektiv spalten sie Ihre Identität in zwei
Teile, von denen eine die Kennung ' Reuschenbach' beibehält,  während die andere
' Beobachter Reuschenbach' aufrufen kann.
Der 'Beobachter Reuschenbach' kann, um den Programmsatz zu überprüfen, die
Konsequenzen von ' Reuschenbach ' auswerten, ihm glauben und feststellen, dass er
korrekt ist, nämlich dass das Teil 'Reuschenbach' diesen Programmsatz tatsächlich
nicht widerspruchsfrei aussagen kann. Für das Teil 'Beobachter Reuschenbach' ist
dieser Programmsatz wahr. Das Teil ' Reuschenbach ' aber kann den Programmsatz
nicht aussagen, da es sonst in einen Selbstwiderspruch verwickelt wird."

Ist das nicht herrlich? Wie ich schon einmal schrieb, "weiss ich darum" dass
ich solche Sätze nicht widerpruchsfrei aussagen könne. Deshalb verwickle ich
mich nicht in keinen "Gödel-Satz für menschliche Turing-Maschinen"
(jedenfalls mein "Wissen darum", dass ich dies nicht kann).

Ich sprach immer "über das Wissen darum", Thümmel spricht davon, dass sich in
solchen Momenten die Identität (ein Programm) spaltet. Also, ein Programm
mit Kennung 'Beobachter Reuschenbach' prüft das für Programm 'Reuschenbach'
unentscheidbare Programm und stellt fest, dass dieses Programm korrekt  und
somit wahr ist.

Im Bewusstein des Reuschenbach - Modells ist von diesen Prozess natürlich nichts
zu merken. Modell 'Reuschenbach' wird nicht plötzlich Schizophren oder hat in
diesen Moment multiple Persönlichkeiten. Dieser eben beschriebene Prozess
äussert sich in 'Penrose' so, dass dieses Modell ausdruckt, es "verstehe"
dass es diesen "Gödel-Satz für menschliche Turing-Maschinen (GSFMTM)" nicht
ausdrucken könne. Modell Reuschenbach mit Kennung 'Reuschenbach' druckt dann eben aus:
[ Dieser Programmsatz ist wahr ]

Aber Modell Reuschenbach mit Kennung 'Reuschenbach' druckt diesen Esan eigentlich
gar nicht aus. Es ist das Programm mit Kennung 'Beobachter Reuschenbach'. Und es
zeigt sich tatsächlich, dass das, was REAL Reuschenbach, aber auch Modell -
Reuschenbach unter: "Ich VERSTEHE dass ich das nicht kann" nichts weiter ist, als
dass Modell - Reuschenbach einfach nicht mitbekommt, was auf seiner Hardware
(oder Wetware) abgeht. Nämlich dass automatisch ein Algorithmus aufgerufen
wird, wenn Input GSFMTM in das Penrose Modell gelangt, der die
Endlosschleife (durch Widerpruch erzeugt) zwar nicht zu stoppen bringt (denn
'Penrose' kann ihn einfach nicht widerspruchsfrei aussagen), aber prft,
dass dieser Algorithmus mit Kennung 'Penrose' nicht anhält, da
unentscheidbar. Dieser Vorgang äussert sich im Bewusstsein des Reuschenbach -
Modells als: Verstehen.

Ist dieser eigentlich Phänomenologische Ausdruck "verstehen" tatsächlich
rechnerisch? Wie wir sahen, ja, er müsste rechnerisch sein. Und eine KI
dürfte mit solchen Programmsätzen keine Probleme haben, wenn sie ein
Problemlösungsverfahren für G implementiert / Programmiert haben.

Wir haben also ein Programm A das prüft, ob ein anderes Programm A* nicht
anhält, wobei A* nicht gestoppt wird und A automatisch stoppt, da A* nicht
anhält. Reuschenbach wird aber nicht Schizophren, und auch ich oder Volkert
werden dies nicht. Es ist nicht so, dass plötzlich diskontinuierliche
Sprünge auftauchen, wenn ich diesen Programmsatz als wahr befinde.

Hier stellen sich Fragen, die u.a nicht nur der KI angehören, sondern auch
der Phänomenologie:

Irgendwie ist A und A* A = A* (ausser wir werden Schizophren)
Wie steht es jetzt um das klassische Halteproblem?
Warum äussert sich der genannte seltsame rechnerische Prozess als
Phänomenologisches "verstehen"?

Und viele andere Fragen, die sich daraus ergeben.


in

Frage

Ja, warum nicht?

nach

Was hält an? Programm mit Kennung 'Volkert' oder Programm mit Kennung
'Beobachter Volkert' oder eben 'Janosch II' (obwohl 'Janosch' & Janosch II'
irgendwie doch ident sind)?

dies

Ich auch nicht.


Aus den oben formulierten, vereinfacht, amüsanten Beispiel ergeben sich
Schwierigkeiten. U.a. ist dieses Beispiel partiell Äquivalent mit Ck(k) und
Co. Ausserdem will ich (in Bezug zur Schizophrenie und multipler
Persönlichkeiten, sowie der Phänomenologie von "verstehen" diesmal mal Peter
sprechen lassen. Obwohl genau dieses Argument des "widerprüchlichen
Programmsatzes" das erste Mal auf Modell - Fatz angewendet wurde, um seine
Thesen zu falsifizieren, hat Fatz wahrscheinlich unbewusst diesen
Kritikpunkt, zugegeben etwas langatmig, schon angesprochen:

"Beim ersten und einfachsten Versuch zu philosophieren verstrickt man sich
in die Frage, ob man, wenn man etwas weiss, weiss, dass man etwas weiss, und
worüber, wenn man von sich selbst denkt, gedacht wird und was das Denken
ausführt.
Nachdem man sich lange mit diesen Problem gequält hat, lernt man nicht
allzusehr auf diesen Problem herumzureiten: Der Begriff eines sich selbst
bewussten Wesens wird implizit als von dem eines sich seiner unbewussten
Objekts verschieden erkannt.  Wenn wir von einem bewussten Wesen behaupten
dass es weiss, dann sagen wir nicht nur dass es etwas weiss, sondern dass es
weiss dass es weiss et cetera. solange wir diese Frage stellen wollen.

Wir erkennen hier etwas unendliches, aber das ist kein unendlicher Regress
im schlechten Sinn, denn es sind Fragen die sich totlaufen, da sie sinnlos
sind, nicht aber die Antworten. Die Fragen kommen einen sinnlos vor, weil
der Begriff in sich selbst die Vorstellung enthält, dass solche Fragen
unendlich lange beantwortet werden können. Wir betrachten auch den Geist als
unendliche Folge von Selbsten und Super - Selbsten und Super-Super-Selbsten.

Doch vielmehr bestehen wir darauf, dass ein bewusstes Wesen eine Einheit
ist, und obgleich wir von Teilen des Geistes sprechen, tun wir dies nur
metaphorisch und lassen es nicht zu, dies wörtlich zu tun. [Ich füge zu
Peter an, dass dies das Neurophysiologische "Binding" Problem ist ]

Die Paradoxien des menschlichen Bewussteins entstehen deshalb, weil ein
bewusstes Wesen sich seiner selbst - und anderer Dinge - bewusst ist und
doch nicht so verstanden werden kann, dass es in Einzelteile auflösbar wäre
[Ich füge zu Peter an, dass Bewusstein ein infiniter Prozess ist, der aber
trotzdem finit verstanden werden kann. Man kann den Ausdruck "Holarchie"
dafür verwenden].

Dass heisst, das ein bewusstes Wesen mit Gödelschen Fragen auf eine Weise
fertig wird, wie es die Maschine nicht kann, weil ein bewusstes Wesen sowohl
sich selbst als auch seine Leistung betrachten kann und doch nichts anderes
ist als das, was diese Leistung vollbrachte.

Eine Maschine kann sozusagen dazu gebracht werden, ihre Leistung zu
"betrachten", aber sie kann dem keine "Rechenschaft" tragen, ohne dabei eine
andere Maschine zu werden [Ich füge zu Peter an, dass Modell - Penrose mit
Kennungen 'Penrose' und 'Penrose II' nicht zu  'Modell-Penrose II' wird ],
nämlich die alte Maschine unter Beifügung  eines "neuen Teils". "

Peter geht noch weiter, aber dies ist hier nicht mehr relevant. Der nun in
diesen posting erwähnte Ansatz ist unausgegoren, aber es ist auch erst 2
Stunden aus, dass mir dieser Ansatz eingefallen ist. Er berührt so ziemlich
alles. Das Halteproblem auf Gödel umgemünzt (Ck(k) und Ak(k)), das
klassische Halteproblem selbst, Phänomenologie des Begriffs "verstehen",
finit und infinite Unterschiede in Bezug auf G Satz, somit auch Unterberger
contra Maderholz, die scheinbar Holarchische Struktur des Bewusstseins, das
Neurophysiologische "Binding" Problem, aufgrund des Gödel - Halteproblems
wieder mal nichtrechnerisches, Identität und Schizophrenie ;)

Liebe Grösse,
Andre Vöcking