Hallo,


Das ist falsch, es sei denn, man schreibt locked-in-Patienten keine 
mentalen Zustände zu.


Dabei hängt es von den verfügbaren Sinnesmodalitäten ab, welche Objekte wie 
identifiziert werden können. Joël verfügt nicht über Augen oder Ohren, aber 
kann beispielsweise Objekte, über die es etwas weiss, anhand einer ihm 
unbekannten Beschreibung identifizieren.


Ich habe von "Nachweisbarkeit im Verhalten geredet...
Sag' mir mal, wie Du bei anderen Menschen mentale Eigenschaften nachweisen 
willst, die keine Auswirkungen auf deren Verhalten haben.


Wobei die Zuordnung von diversen Dingen in der Umgebung des Teichs und vom 
Beobachtungszeitpunkt abhängt...
Wenn Du nur einfach physikalischen Parametern des Teiches bijektiv gewisse 
Lautsprechersignale zuordnest und in den Teich hineinsprichst, wird 
unabhängig von der fest gewählten Bijektion kein Gespräch zustandekommen. 
Der Teich wird den Turing-Test nicht bestehen.
Wenn sich dagegen ein System, das einen Teich enthält, plötzlich mit mir 
unterhält, dann sehe ich darin einen sehr guten Grund, dem Ding, das die 
Output-Einheiten steuert, Intelligenz zuzuschreiben.
Und nochmals die Frage, die Du nicht beantworten wolltest: würdest Du einem 
Ausserirdischen auch erst glauben, daß er intelligent ist, nachdem Du ihn 
seziert hast, um festzustellen, ob sein Gehirn auch dem eines Menschen 
gleicht?


Zwischen Systemen, die gleich viel Information enthalten, kann man immer 
eine Bijektion finden, aber diese Bijektion wird in aller Regel kein 
Isomorphismus sein. Und damit der Teich in einer Unterhaltung erfolgreich 
ist, muss er isomorph sein zu einem System, das den Turing-Test besteht.


Das KI-Projekt muss schon eine schlimme Kränkung der Arroganz mancher 
Menschen darstellen - KI-Gegner werden immer gleich so aggressiv 
*ggggg*....


Ich habe eher eine Vorstellung einer unbeseelten Welt, in der es aber eben 
denkende Systeme geben kann. Und wenn das System aus dem Teich und 
umliegenden Apparaten mit mir reden kann, dann finde ich, daß die Hypothese 
sehr plausibel ist, daß dieses System von etwas gesteuert wird, das denkt.


Nein, es wird nur jedes System, das einen Turing-Test besteht, durch eine 
denkende Struktur gesteuert. Im Experiment des chinesischen Zimmers steuert 
nicht Altweck die chinesischen Antworten, sondern das auf Englisch 
geschriebene Programm, das Altweck ausführt. Deswegen versteht Altweck auch 
nichts von dem Output des Programmes.

Größe,
Ludger.