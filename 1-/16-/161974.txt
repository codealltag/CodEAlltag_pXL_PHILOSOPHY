Moment: Es ging ja nicht um die Fehlerlosigkeit an sich, sondern um
die Fehlerlosigkeit einer digitalen Simulation eines analogen
Vorgangs. Letzterer hat keine "Fehlerkorrektur", denn er ist selbst
das zu simulierende Seiende. Die Fehlerkorrektur ist also nur möglich,
wenn ich das Errechnete mit dem Seienden vergleiche, also den
errechneten Standort eines 3er Pendels mit dem tatsächlichen Standort
dieses Pendels nach der Zeit X. Der Rechner braucht die
Fehlerkorrektur, der Pendel nicht. Nehme ich den Pendel weg, ist eine
Fehlerkorrektur nicht möglich. Da die Ausgangssituation des Pendels
feststeht, der Rechner aber keinen Zugang zum Pendel zum Abgleich hat,
so muß zwangsläufig das Ergebnis von der Wirklichkeit abweichen. Trotz
aller Widerspruchsfreiheit mit irgendwelchen Erhaltungssätzen ist das
Ergebnis falsch. Denn das richtige Ergebnis liefert das Pendel in
Natur.


1. wieso ist das Chaos nicht simulierbar? Ich denke alles ist bei Dir
simulierbar.
2. Ob die Steuerung eines Androiden in Deinem Sinne funktionieren
würde, ist dann nur noch eine Frage der Wertung. (Versteckt sich bei
Dir im Begriff "menschenähnlich")


Da steckt in der Voraussetzung ("Wenn ...) bereits das Ergebnis drin.


Und mir ist "anwendbar" zu schwammig. Da kommt's drauf an, wer was
beweisen muß. Ob wirklich alle Einfälle (Achtung: Allsatz!) des
Menschen Rekombinationen aus bekanntem sind, müßte bewiesen werden.
Dazu genügt nicht, daß man rein semantisch Beispiele bringt oder
fragt: "Warum nicht?" und ähnliches.


Nein, Großmeister nicht.


Schon, nur wenn es auch in der Roboterregierung Skandale gibt, lohnt
der Aufwand der KI nicht.
Außerdem möchte ich einem Roboter dieser Art z.B. nicht die Erziehung
meiner Kinder anvertrauen.


Das kommt auf die Toleranzbreite beim Würt "ähnlich" an.
Aber dann stellt sich natürlich die Prinzipielle Frage, was
Intelligenz ist. Wenn damit digitale Problemlösung gemeint ist, dann
wird ein bestimmter Teil des Menschen davon wohl erfaßt werden können.
Wenn es um Problemlösung schlechthin geht, dann ist ein Fluß bereits
intelligent, weil er das Problem, zum Meer zu gelangen, optimal löst.


Ich habe auch nicht gesagt, daß es schlimm wäre. Außerdem meine ich
schon, daß es schon beim Menschen schlimm ist, warum dann beim
Computer nicht? Aber Du redest von "manchesmal". Ich glaube, komplexe
Programme, die nur "manchesmal" fehlreagieren, kann man an einer Hand
abzählen. Und die sind trotz ihrer im Vergleich zu dem von Dir ins
Auge gefaßten Programmen geradezu steinzeitlichen Einfachheit kaum
noch in akzeptabler Zeit auszutesten.

Die prinzipielle Frage besteht aber fort, ob diese Gemeinschaft in der
Lage sein wird, auch ein Testprogramm zu schreiben, das die
Programmierfehler dingfest macht.


Das aber zum Zwecke der Operationalisierung digitalisieren müßte,
damit bits draus werden können.

Gruss Ludger