kein problem, mit dieser sichtweise kann ich mich durchaus anfreuden.

nun verrate mir aber mal, inwiefern uns das von einer scheinbar
intelligenten maschine unterscheiden würde?

stell dir vor, unsere maschine kann sowohl seine umwelt wahrnehmen,
als auch manipulieren. durch einen *zufall wäre es möglich, dass
sich diese maschine mit hilfe ihrer sensoren (kamera etc.) selbst
sieht und sich bezüglich einer gegebenen aufgabenstellung (z.b.
einfach nur intakt zu bleiben) als interessant bzw. bedeutungsvoll
ansieht.

durch integrierte werkzeuge (l�tkolben, schneidbrenner) könnte diese
maschine anfangen, sich selbst zu analysieren/zerlegen...
selbstverständlich ohne das wissen, dass sie sich gerade selbst
beschädigt (--> fehlendes bewusstsein?).

jedoch würde diese maschine durch andere sensoren registrieren, dass
das ziel, intakt zu bleiben, plötzlich gefährdet ist (vorausgesetzt,
die maschine hat nicht unglücklicherweise seine stromversorgung
gekappt :)

wenn die maschine mit hilfe ihrer integrierten sensoren keinen
äusseren einfluss ausmachen kann besteht eigentlich nur noch die
möglichkeit, dass diese gefahrensituation durch das eigene handeln
entstanden ist.

folglich speichert die maschine diese aktionen als gefährlich, um
sie in zukunft zu vermeiden (natürlich immer noch ohne begriffen
zu haben, dass sie sich selbst beschädigt hat).

beim nächsten mal würde die maschine in ihrem gedächtnis finden:
"diese aktion ist zu vermeiden".

die maschine hat weder die bedeutung dieser information begriffen,
noch hat sie verstanden, welche auswirkungen das ausführen dieser
aktion hätte. der algorithmus verhindert jedoch einen erneuten
selbstverst�mmelungsversuch. allerdings könnte die maschine auch
einen separaten algorithmus starten, um die auswirkungen eines
solchen versuches zu simulieren, um zu entscheiden, ob die aktion
sinnvoll oder gefährlich (im sinne der aufgabenstellung) ist.

wenn wir unsere maschine zusätzlich beauftragen, andere maschinen
zu eliminieren, dann könnte sie mit hilfe dieses separaten
algorithmus (unterprozess) simulieren, wie sich die aktionen auf
eine andere maschine auswirken könnten. natürlich wäre dieses
programm bereits äusserst kompliziert, grundsätzlich spricht
jedoch erstmal nichts gegen eine realisierung (wenn JPZS
mal schnell 1000 leute damit beschäftigt, könnten diese das
vielleicht in 5 oder 10 jahren schaffen....natürlich müsste man
diese maschine des öfteren per hand reanimieren, da sie
gelegentlich einem spontanen unerklärbaren tod unterliegt ;)


ich traue mich nun gar nicht, zu fragen, inwiefern sich das
bewusstsein der maschine von unserem unterscheidet (von der
komplexität einmal abgesehen).

was ich nur wissen möchte ist, wie DU als mensch feststellen willst,
ob eine derartige (u.U. noch sehr viel umfangreichere) maschine
intelligent ist bzw. ein bewusstsein hat, oder nicht. daher auch
die Überschrift dieses threads ("Intelligenz vs. scheinbare
Intelligenz").


j3rky