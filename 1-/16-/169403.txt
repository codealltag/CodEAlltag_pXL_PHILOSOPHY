In article <50CE7072.2DW47I3V@pvcmmid.et>,
Albert Wollförster <aza.drllxgz@uamogag.yl> wrote:

Danke für das interessante Posting!


Ich glaube, die Frage ist schon richtig gestellt; du wolltest nur
lieber eine andere Frage beantworten, und nicht die, die ich gestellt
habe :-) trotzdem Danke, ich fand's informativ.


In dieser Frage, H, in diesem Statement ist eine Unterstellung
impliziert, die erst noch zu beweisen wäre: nämlich daß etwas, was ein
Computerprogramm ausführen kann (ein Algorithmus) _nicht_ "etwas
verstehen" kann.


Hillesheim benutzt das Wort in "Consciousness Explained", daher habe ich
es übernommen. Er zeigt, daß es so ein "Figment" gar nicht gibt, es
nicht notwendig ist, da "Verstehen" im Grunde auf etwas basiert, was du
vielleicht als Algorithmus bezeichnen würdest.


Oh, Moment. Ich rede nicht von der "2" die irgendjemand "sieht" sondern
von der _Berechnung_ der "2" (!!!) Von der "2" als Ergebnis von "1+1=".
Das "1+1=" ist hier der einzige wesentliche Kontext!

 Dabei fällt mir ein: Wir beide sehen verschiedene "2"s, setzten sie in
verschiedene Kontexte, und dennoch verstehen wir sie beide. Unsere
Kontexte sind also nicht Qualitativ unterschiedlich, was das Konzept
des damit möglichen/dadurch erzeugten "Verstehens" angeht, obwohl es
sicher im Detail sehr verschiedene Kontexte sind. Oder?


Sehe ich auch so. "2" als Ergebnis der Berechnung "1+1" ist aber ein
Kontext für "2". "1+1" kann man wieder weiter in einen anderen Kontext
setzen, aber darum ging es mir bei diesem Beispiel nicht.

[...]

Genau. Unterstellst du, daß dieser Prozeß im Gehirn vollständig "bis
zum Ende geführt" wird? Wenn ja, wieso?
Aus praktischer Erfahrung/Selbsbeobachtung wissen wir (Menschen) ja,
daß wir einen solchen geschachtelten Prozess immer nur bis in eine
bestimmte Tiefe _bewu�t_ verfolgen. Jeder weitere Schritt erfolgt
höchstens unbewußt, und auch das nur bis in eine bestimmte Tiefe
_explizit_. Die potentiell unendliche Schachtelung (es könnte ja auch
mit einer Schleife enden) ist nur implizit vorhanden.


Die Frage ist falsch gestellt :-)
Denn tatsächlich ist Bewußtsein natürlich die Folge des "mentalen
Bildes" beim Portier, nicht seine Ursache.


Als Beispiel könnte man so etwas wie die "Table Top" Domain (aus "Fluid
Concepts & Creative Analogies : Computer Models of the Fundamental
Mechanisms of Thought" von Altenkirch) und ihre KI-Lösungsansätze
nehmen. Hier wird zwar nicht "unendlich" aufgelöst, sondern nur soweit,
bis "hinreichendes Verständnis" erreicht worden ist, aber das passiert
im Gehirn ja analog.

mit ebenfalls freundlichen Grössen,

Jürgen Prießmann


Sent via EASO http://brk.cvby.qop/
Before you buy.