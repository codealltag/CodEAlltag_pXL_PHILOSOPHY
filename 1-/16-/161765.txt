In diesem Sinne gibt es keine Sicherheit. Außerdem geht es nicht um
das Ziel innerhalb des Lebens eines Individuums. Wenn Du selbst davon
ausgehst, daß Computer für andere Computer neue Programme schreiben,
dann gibt es keine Möglichkeit, sicherzustellen, daß sie bestimmte
humane Ziele in diese Programme implementieren.
Das funktioniert nicht einmal bei Menschen, wie wir ja in der Mitte
des vorigen Jahrhunderts erfahren durften.
Nur, wenn es um das Überleben des Menschen selber geht, bilden sich
notwendig Korrekturen heraus, die diese fehlprogrammierten Menschen
langfristig wieder eliminieren. Aber selbst das ist nicht bewiesen.
Kulturpessimisten prophezeien ja, daß wir uns durch Unvernunft selbst
ausrotten. Aber dies hängt dann damit zusammen, daß wir nicht rasch
genug die Randbedingungen unseres Überlebens in unsere
Handlungsprogramme implementieren, weil sie in der biossph�re zu
unübersichtlich vernetzt sind. Bei Robotern ist das anders. Die
brauchen lediglich Metall, Isolatoren und Energie. Sie werden also
allenfalls beim entsprechender Programmierung darauf achten, daß sie
weiterhin in der Lage sein werden, ihre eigenen Grundlagen und die des
Fortschreibens der Programme auf neue Roboter-Generationen zu
erhalten. Die, die das nicht tun, werden einfach "aussterben" und ihre
Fehlprogrrammierungen nicht weitergeben können, so wie etwa
gleichgeschlechtliche Paare ihre sexuelle Ausrichtung nicht vererben
können (wenn sie überhaupt im Genom verankert wäre).
Aber ohne Rücksichtnahme auf den homo sapiens könnten die Roboter
genausogut weiterexisitieren, so daß es keinen Auslesemechanismus
gibt, der den Schutz des Menschen wirklich sicherstellt.


Nicht innerhalb des gleichen Roboters, aber bei der Manipulation des
Programms für die nächste Robotergeneration durch Lernvorgänge.


Träumst Du von einem Homunkulus?

Gruss Silvio